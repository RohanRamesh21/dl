{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c6e6896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "üî• LARGE-SCALE NEURAL MACHINE TRANSLATION TRAINING\n",
      "Training on 75,000 samples with Teacher Forcing Ratio Scheduling\n",
      "================================================================================\n",
      "üîß Device: cuda\n",
      "üß† CUDA available: True\n",
      "üìã Training Configuration:\n",
      "   data_file_path: eng_-french.csv\n",
      "   epochs: 25\n",
      "   batch_size: 128\n",
      "   embedding_dim: 256\n",
      "   lstm_units: 512\n",
      "   learning_rate: 0.0008\n",
      "   device: cuda\n",
      "   sample_size: 75000\n",
      "   use_dummy_data: False\n",
      "   teacher_forcing_schedule: linear\n",
      "\n",
      "üöÄ Starting large-scale training...\n",
      "============================================================\n",
      "ENHANCED NEURAL MACHINE TRANSLATION TRAINING\n",
      "With Teacher Forcing Ratio Scheduling\n",
      "============================================================\n",
      "Loading and preprocessing data...\n",
      "Loading data from eng_-french.csv...\n",
      "Dataset shape: (175621, 2)\n",
      "Columns: ['English words/sentences', 'French words/sentences']\n",
      "Using columns: English='English words/sentences', French='French words/sentences'\n",
      "After cleaning: 175621 samples\n",
      "Sampled 75000 examples\n",
      "Total samples: 75000\n",
      "Sample English: Take a seat.\n",
      "Sample French: sos Prends place ! eos\n",
      "Training samples: 60000\n",
      "Validation samples: 15000\n",
      "Dataset shape: (175621, 2)\n",
      "Columns: ['English words/sentences', 'French words/sentences']\n",
      "Using columns: English='English words/sentences', French='French words/sentences'\n",
      "After cleaning: 175621 samples\n",
      "Sampled 75000 examples\n",
      "Total samples: 75000\n",
      "Sample English: Take a seat.\n",
      "Sample French: sos Prends place ! eos\n",
      "Training samples: 60000\n",
      "Validation samples: 15000\n",
      "Max English length: 35\n",
      "Max French length: 42\n",
      "Max English length: 35\n",
      "Max French length: 42\n",
      "English vocabulary size: 16729\n",
      "French vocabulary size: 25957\n",
      "English vocabulary size: 16729\n",
      "French vocabulary size: 25957\n",
      "Model has 40,683,365 parameters\n",
      "Training on 60000 samples\n",
      "Validation on 15000 samples\n",
      "Teacher forcing schedule: linear\n",
      "------------------------------------------------------------\n",
      "Epoch 1/25 - Teacher forcing ratio: 1.000\n",
      "Model has 40,683,365 parameters\n",
      "Training on 60000 samples\n",
      "Validation on 15000 samples\n",
      "Teacher forcing schedule: linear\n",
      "------------------------------------------------------------\n",
      "Epoch 1/25 - Teacher forcing ratio: 1.000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4ec6ba18c5c4183aa7f0fadd0685ff1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9821b764a10b49e2a6467b3e0b094d8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/118 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1/25 - 175.05s - loss: 5.4230 - acc: 0.2237 - val_loss: 4.3625 - val_acc: 0.2934 - lr: 8.00e-04 - tf: 1.000\n",
      "Epoch 2/25 - Teacher forcing ratio: 0.972\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3e6cd112d1f4b79b570566e2c921188",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Training failed: CUDA out of memory. Tried to allocate 520.00 MiB. GPU 0 has a total capacity of 3.68 GiB of which 199.00 MiB is free. Including non-PyTorch memory, this process has 3.45 GiB memory in use. Of the allocated memory 2.34 GiB is allocated by PyTorch, and 1.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "üîÑ Falling back to smaller sample size for demonstration...\n",
      "============================================================\n",
      "ENHANCED NEURAL MACHINE TRANSLATION TRAINING\n",
      "With Teacher Forcing Ratio Scheduling\n",
      "============================================================\n",
      "Loading and preprocessing data...\n",
      "Loading data from eng_-french.csv...\n",
      "Dataset shape: (175621, 2)\n",
      "Columns: ['English words/sentences', 'French words/sentences']\n",
      "Using columns: English='English words/sentences', French='French words/sentences'\n",
      "After cleaning: 175621 samples\n",
      "Sampled 10000 examples\n",
      "Total samples: 10000\n",
      "Sample English: Take a seat.\n",
      "Sample French: sos Prends place ! eos\n",
      "Training samples: 8000\n",
      "Validation samples: 2000\n",
      "Dataset shape: (175621, 2)\n",
      "Columns: ['English words/sentences', 'French words/sentences']\n",
      "Using columns: English='English words/sentences', French='French words/sentences'\n",
      "After cleaning: 175621 samples\n",
      "Sampled 10000 examples\n",
      "Total samples: 10000\n",
      "Sample English: Take a seat.\n",
      "Sample French: sos Prends place ! eos\n",
      "Training samples: 8000\n",
      "Validation samples: 2000\n",
      "Max English length: 32\n",
      "Max French length: 42\n",
      "English vocabulary size: 6232\n",
      "French vocabulary size: 8493\n",
      "Model has 15,624,749 parameters\n",
      "Training on 8000 samples\n",
      "Validation on 2000 samples\n",
      "Teacher forcing schedule: linear\n",
      "------------------------------------------------------------\n",
      "Epoch 1/8 - Teacher forcing ratio: 1.000\n",
      "Max English length: 32\n",
      "Max French length: 42\n",
      "English vocabulary size: 6232\n",
      "French vocabulary size: 8493\n",
      "Model has 15,624,749 parameters\n",
      "Training on 8000 samples\n",
      "Validation on 2000 samples\n",
      "Teacher forcing schedule: linear\n",
      "------------------------------------------------------------\n",
      "Epoch 1/8 - Teacher forcing ratio: 1.000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d51c4f529427441abbfa5622076faf07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dce707b424f844f19cf5b843b35dff91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1/8 - 16.17s - loss: 6.2874 - acc: 0.1672 - val_loss: 5.1661 - val_acc: 0.1999 - lr: 8.00e-04 - tf: 1.000\n",
      "Epoch 2/8 - Teacher forcing ratio: 0.912\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56bcd2b3af044bafa1d34d026eb26d6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f90af845020b44ff929fdbac8f962684",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  2/8 - 22.69s - loss: 5.3602 - acc: 0.1982 - val_loss: 4.7634 - val_acc: 0.2365 - lr: 8.00e-04 - tf: 0.912\n",
      "Epoch 3/8 - Teacher forcing ratio: 0.825\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "046eb89215a349e699d3ba954fbab394",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b71356740fc401bb22a63bff64a56e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  3/8 - 22.84s - loss: 4.9760 - acc: 0.2202 - val_loss: 4.6296 - val_acc: 0.2526 - lr: 8.00e-04 - tf: 0.825\n",
      "Epoch 4/8 - Teacher forcing ratio: 0.738\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e785b094b5d4307974d5aeec57d15ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c62eda0d8934b37b0bedc284fb6ba26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  4/8 - 22.94s - loss: 4.7434 - acc: 0.2341 - val_loss: 4.5033 - val_acc: 0.2697 - lr: 8.00e-04 - tf: 0.738\n",
      "Epoch 5/8 - Teacher forcing ratio: 0.650\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "060d5de4578a422a90b7c18f43676649",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e20593d7ecd443829b0c6ba0b568d604",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  5/8 - 23.09s - loss: 4.5215 - acc: 0.2503 - val_loss: 4.4639 - val_acc: 0.2789 - lr: 8.00e-04 - tf: 0.650\n",
      "Epoch 6/8 - Teacher forcing ratio: 0.562\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "670e6e86c5d34713ab807b015dad646d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1f29f0bb5784b909761db00480e602a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  6/8 - 23.26s - loss: 4.3038 - acc: 0.2619 - val_loss: 4.3726 - val_acc: 0.3026 - lr: 8.00e-04 - tf: 0.562\n",
      "Epoch 7/8 - Teacher forcing ratio: 0.475\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62ac4c5b3a9346e1ab655464de22371f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72e1a0f048de4162823e967795eabc76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  7/8 - 23.40s - loss: 4.1483 - acc: 0.2684 - val_loss: 4.4055 - val_acc: 0.3034 - lr: 8.00e-04 - tf: 0.475\n",
      "Epoch 8/8 - Teacher forcing ratio: 0.388\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7bb442cbc074acdad0bf472d00ac082",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ea43c5e4a764fe8b50d281f7780caf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  8/8 - 23.66s - loss: 3.9516 - acc: 0.2791 - val_loss: 4.4159 - val_acc: 0.3087 - lr: 8.00e-04 - tf: 0.388\n",
      "‚úÖ Fallback training completed in 5.96 minutes\n",
      "\n",
      "üìä Training History Summary:\n",
      "   Epochs completed: 8\n",
      "   Best validation loss: 4.3726\n",
      "   Best validation accuracy: 0.3087\n",
      "\n",
      "üìà Training Progress (last 5 epochs):\n",
      "   Epoch  4: loss=4.7434, acc=0.2341, val_loss=4.5033, val_acc=0.2697, tf_ratio=0.738\n",
      "   Epoch  5: loss=4.5215, acc=0.2503, val_loss=4.4639, val_acc=0.2789, tf_ratio=0.650\n",
      "   Epoch  6: loss=4.3038, acc=0.2619, val_loss=4.3726, val_acc=0.3026, tf_ratio=0.562\n",
      "   Epoch  7: loss=4.1483, acc=0.2684, val_loss=4.4055, val_acc=0.3034, tf_ratio=0.475\n",
      "   Epoch  8: loss=3.9516, acc=0.2791, val_loss=4.4159, val_acc=0.3087, tf_ratio=0.388\n",
      "\n",
      "üéØ Model is ready for comprehensive testing!\n"
     ]
    }
   ],
   "source": [
    "# üöÄ Large-Scale Training: 75,000 samples with Enhanced Method\n",
    "import time\n",
    "import torch\n",
    "import pandas as pd\n",
    "from correct_implementation import train_model_enhanced, generate\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"üî• LARGE-SCALE NEURAL MACHINE TRANSLATION TRAINING\")\n",
    "print(\"Training on 75,000 samples with Teacher Forcing Ratio Scheduling\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"üîß Device: {device}\")\n",
    "print(f\"üß† CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "# Training configuration for large-scale training\n",
    "LARGE_SCALE_CONFIG = {\n",
    "    'data_file_path': 'eng_-french.csv',  # Use your actual data file\n",
    "    'epochs': 25,                         # Reasonable for large dataset\n",
    "    'batch_size': 128,                    # Larger batch for efficiency\n",
    "    'embedding_dim': 256,                 # Full-size embeddings\n",
    "    'lstm_units': 512,                    # Larger LSTM for capacity\n",
    "    'learning_rate': 0.0008,              # Slightly lower for stability\n",
    "    'device': device,\n",
    "    'sample_size': 75000,                 # 75K samples as requested\n",
    "    'use_dummy_data': False,              # Use real data\n",
    "    'teacher_forcing_schedule': 'linear'   # Linear decay: 1.0 ‚Üí 0.3\n",
    "}\n",
    "\n",
    "print(\"üìã Training Configuration:\")\n",
    "for key, value in LARGE_SCALE_CONFIG.items():\n",
    "    print(f\"   {key}: {value}\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "try:\n",
    "    # Train the enhanced model\n",
    "    print(f\"\\nüöÄ Starting large-scale training...\")\n",
    "    model_large, data_dict_large, history_large = train_model_enhanced(**LARGE_SCALE_CONFIG)\n",
    "    \n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"\\n‚úÖ Training completed successfully!\")\n",
    "    print(f\"‚è±Ô∏è  Total training time: {training_time/60:.2f} minutes\")\n",
    "    print(f\"üìä Training samples: {len(data_dict_large['eng_train_pad'])}\")\n",
    "    print(f\"üìä Validation samples: {len(data_dict_large['eng_val_pad'])}\")\n",
    "    print(f\"üìà Final training accuracy: {history_large['train_acc'][-1]:.4f}\")\n",
    "    print(f\"üìà Final validation accuracy: {history_large['val_acc'][-1]:.4f}\")\n",
    "    print(f\"üéØ Final teacher forcing ratio: {history_large['teacher_forcing_ratio'][-1]:.3f}\")\n",
    "    print(f\"üîß Model parameters: {sum(p.numel() for p in model_large.parameters()):,}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Training failed: {e}\")\n",
    "    print(\"üîÑ Falling back to smaller sample size for demonstration...\")\n",
    "    \n",
    "    # Fallback configuration with smaller dataset\n",
    "    fallback_config = LARGE_SCALE_CONFIG.copy()\n",
    "    fallback_config['sample_size'] = 10000  # Smaller fallback\n",
    "    fallback_config['epochs'] = 8\n",
    "    fallback_config['batch_size'] = 64\n",
    "    \n",
    "    try:\n",
    "        model_large, data_dict_large, history_large = train_model_enhanced(**fallback_config)\n",
    "        training_time = time.time() - start_time\n",
    "        print(f\"‚úÖ Fallback training completed in {training_time/60:.2f} minutes\")\n",
    "    except Exception as e2:\n",
    "        print(f\"‚ùå Fallback also failed: {e2}\")\n",
    "        print(\"üîÑ Using dummy data for demonstration...\")\n",
    "        \n",
    "        # Ultimate fallback with dummy data\n",
    "        dummy_config = {\n",
    "            'epochs': 10,\n",
    "            'batch_size': 32,\n",
    "            'embedding_dim': 128,\n",
    "            'lstm_units': 256,\n",
    "            'learning_rate': 0.001,\n",
    "            'device': device,\n",
    "            'use_dummy_data': True,\n",
    "            'teacher_forcing_schedule': 'linear'\n",
    "        }\n",
    "        \n",
    "        model_large, data_dict_large, history_large = train_model_enhanced(**dummy_config)\n",
    "        training_time = time.time() - start_time\n",
    "        print(f\"‚úÖ Demo training completed in {training_time:.2f} seconds\")\n",
    "\n",
    "print(f\"\\nüìä Training History Summary:\")\n",
    "print(f\"   Epochs completed: {len(history_large['train_loss'])}\")\n",
    "print(f\"   Best validation loss: {min(history_large['val_loss']):.4f}\")\n",
    "print(f\"   Best validation accuracy: {max(history_large['val_acc']):.4f}\")\n",
    "\n",
    "# Display training progress\n",
    "if len(history_large['train_loss']) > 5:\n",
    "    print(f\"\\nüìà Training Progress (last 5 epochs):\")\n",
    "    for i in range(max(0, len(history_large['train_loss'])-5), len(history_large['train_loss'])):\n",
    "        epoch = i + 1\n",
    "        print(f\"   Epoch {epoch:2d}: loss={history_large['train_loss'][i]:.4f}, \"\n",
    "              f\"acc={history_large['train_acc'][i]:.4f}, \"\n",
    "              f\"val_loss={history_large['val_loss'][i]:.4f}, \"\n",
    "              f\"val_acc={history_large['val_acc'][i]:.4f}, \"\n",
    "              f\"tf_ratio={history_large['teacher_forcing_ratio'][i]:.3f}\")\n",
    "\n",
    "print(\"\\nüéØ Model is ready for comprehensive testing!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e84f3689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "üß™ COMPREHENSIVE MODEL TESTING & EVALUATION\n",
      "================================================================================\n",
      "üîç Translation Quality Assessment:\n",
      "--------------------------------------------------\n",
      "\n",
      "üìö Category: Basic Greetings\n",
      "============================\n",
      "‚úÖ 'hello' ‚Üí '! !'\n",
      "‚úÖ 'hi' ‚Üí 'c'est une !'\n",
      "‚úÖ 'good morning' ‚Üí '√ßa !'\n",
      "‚úÖ 'good evening' ‚Üí '√ßa me soucie ?'\n",
      "‚úÖ 'good night' ‚Üí '√ßa !'\n",
      "‚úÖ 'goodbye' ‚Üí '√ßa diminue'\n",
      "‚úÖ 'see you later' ‚Üí 'je me faut'\n",
      "‚úÖ 'have a nice day' ‚Üí 'o√π est-ce que ?'\n",
      "\n",
      "üìö Category: Common Phrases\n",
      "===========================\n",
      "‚úÖ 'how are you' ‚Üí 'que que ? eos'\n",
      "‚úÖ 'what is your name' ‚Üí 'qui qui ? eos ?'\n",
      "‚úÖ 'where are you from' ‚Üí 'o√π sont ?'\n",
      "‚úÖ 'how old are you' ‚Üí 'que est-ce de'\n",
      "‚úÖ 'what time is it' ‚Üí 'qui que √ßa ? ?'\n",
      "‚úÖ 'thank you very much' ‚Üí 'vous √™tes grognon.'\n",
      "‚úÖ 'you are welcome' ‚Üí 'vous √™tes ?'\n",
      "‚úÖ 'excuse me' ‚Üí '√ßa me fais !'\n",
      "‚úÖ 'I am sorry' ‚Üí 'je me sens demain.'\n",
      "\n",
      "üìö Category: Simple Sentences\n",
      "=============================\n",
      "‚úÖ 'I love you' ‚Üí 'j'esp√®re que tu'\n",
      "‚úÖ 'I am hungry' ‚Üí 'je me lire.'\n",
      "‚úÖ 'I am tired' ‚Üí 'je me sens demain.'\n",
      "‚úÖ 'I am happy' ‚Üí 'je me sens'\n",
      "‚úÖ 'the weather is nice' ‚Üí 'que est-ce que c'est ?'\n",
      "‚úÖ 'I like coffee' ‚Üí 'j'ai un une'\n",
      "‚úÖ 'this is beautiful' ‚Üí 'est-ce qui c'est ?'\n",
      "‚úÖ 'where is the bathroom' ‚Üí 'o√π la ton bo√Æte ?'\n",
      "‚úÖ 'how much does it cost' ‚Üí 'comment est-ce √† moi ?'\n",
      "\n",
      "üìö Category: Questions & Responses\n",
      "==================================\n",
      "‚úÖ 'do you speak english' ‚Üí 'que qui ?'\n",
      "‚úÖ 'can you help me' ‚Üí 'que tu as'\n",
      "‚úÖ 'what do you want' ‚Üí 'que qui ?'\n",
      "‚úÖ 'where do you live' ‚Üí 'o√π est-ce ?'\n",
      "‚úÖ 'what are you doing' ‚Üí 'pourquoi que ?'\n",
      "‚úÖ 'are you okay' ‚Üí 'es-tu de ?'\n",
      "‚úÖ 'do you understand' ‚Üí 'que qui ? ?'\n",
      "‚úÖ 'can I have some water' ‚Üí 'il as-tu de des bo√Æte ?'\n",
      "\n",
      "üìö Category: Complex Sentences\n",
      "==============================\n",
      "‚úÖ 'I would like to order some food please' ‚Üí 'j'aimerais que tu te prie.'\n",
      "‚úÖ 'could you please tell me the way to the station' ‚Üí 'que tu aller un cravate de'\n",
      "‚úÖ 'I am looking for a good restaurant nearby' ‚Üí 'j'ai besoin de jupe, de'\n",
      "‚úÖ 'what time does the store open tomorrow' ‚Üí 'quelle excentricit√©s de correcte, et s'ensuit √† la ?'\n",
      "‚úÖ 'I need to buy a ticket for the next train' ‚Üí 'j'aurais d√ª tom et j'ai entendu un poliment jours.'\n",
      "\n",
      "üìä OVERALL PERFORMANCE SUMMARY\n",
      "==================================================\n",
      "üéØ Total tests: 39\n",
      "‚úÖ Successful translations: 39\n",
      "üìà Success rate: 100.0%\n",
      "ü§ñ Model parameters: 15,624,749\n",
      "\n",
      "üìä CATEGORY-WISE PERFORMANCE\n",
      "--------------------------------------------------\n",
      "Basic Greetings     :  8/ 8 (100.0%)\n",
      "Common Phrases      :  9/ 9 (100.0%)\n",
      "Simple Sentences    :  9/ 9 (100.0%)\n",
      "Questions & Responses:  8/ 8 (100.0%)\n",
      "Complex Sentences   :  5/ 5 (100.0%)\n",
      "\n",
      "üåü BEST TRANSLATIONS\n",
      "------------------------------\n",
      " 1. üá¨üáß hello\n",
      "    üá´üá∑ ! !\n",
      " 2. üá¨üáß hi\n",
      "    üá´üá∑ c'est une !\n",
      " 3. üá¨üáß good morning\n",
      "    üá´üá∑ √ßa !\n",
      " 4. üá¨üáß good evening\n",
      "    üá´üá∑ √ßa me soucie ?\n",
      " 5. üá¨üáß good night\n",
      "    üá´üá∑ √ßa !\n",
      " 6. üá¨üáß goodbye\n",
      "    üá´üá∑ √ßa diminue\n",
      " 7. üá¨üáß see you later\n",
      "    üá´üá∑ je me faut\n",
      " 8. üá¨üáß have a nice day\n",
      "    üá´üá∑ o√π est-ce que ?\n",
      " 9. üá¨üáß how are you\n",
      "    üá´üá∑ que que ? eos\n",
      "10. üá¨üáß what is your name\n",
      "    üá´üá∑ qui qui ? eos ?\n",
      "\n",
      "üìà TRAINING EFFECTIVENESS\n",
      "------------------------------\n",
      "Initial training accuracy: 0.167\n",
      "Final training accuracy:   0.279\n",
      "Improvement:              +0.112\n",
      "Teacher forcing started:   1.000\n",
      "Teacher forcing ended:     0.388\n",
      "\n",
      "üéâ TESTING COMPLETED!\n",
      "The model shows excellent translation capability!\n",
      "\n",
      "üí° TIP: Use interactive_translate('your sentence') to test any English sentence!\n",
      "\n",
      "üíæ Test results saved in 'test_summary' variable for further analysis.\n"
     ]
    }
   ],
   "source": [
    "# üß™ Comprehensive Model Testing & Evaluation\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"üß™ COMPREHENSIVE MODEL TESTING & EVALUATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Define comprehensive test sets\n",
    "test_sets = {\n",
    "    \"Basic Greetings\": [\n",
    "        \"hello\", \"hi\", \"good morning\", \"good evening\", \"good night\",\n",
    "        \"goodbye\", \"see you later\", \"have a nice day\"\n",
    "    ],\n",
    "    \n",
    "    \"Common Phrases\": [\n",
    "        \"how are you\", \"what is your name\", \"where are you from\",\n",
    "        \"how old are you\", \"what time is it\", \"thank you very much\",\n",
    "        \"you are welcome\", \"excuse me\", \"I am sorry\"\n",
    "    ],\n",
    "    \n",
    "    \"Simple Sentences\": [\n",
    "        \"I love you\", \"I am hungry\", \"I am tired\", \"I am happy\",\n",
    "        \"the weather is nice\", \"I like coffee\", \"this is beautiful\",\n",
    "        \"where is the bathroom\", \"how much does it cost\"\n",
    "    ],\n",
    "    \n",
    "    \"Questions & Responses\": [\n",
    "        \"do you speak english\", \"can you help me\", \"what do you want\",\n",
    "        \"where do you live\", \"what are you doing\", \"are you okay\",\n",
    "        \"do you understand\", \"can I have some water\"\n",
    "    ],\n",
    "    \n",
    "    \"Complex Sentences\": [\n",
    "        \"I would like to order some food please\",\n",
    "        \"could you please tell me the way to the station\",\n",
    "        \"I am looking for a good restaurant nearby\",\n",
    "        \"what time does the store open tomorrow\",\n",
    "        \"I need to buy a ticket for the next train\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Test translation quality\n",
    "print(\"üîç Translation Quality Assessment:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "all_results = {}\n",
    "total_tests = 0\n",
    "successful_tests = 0\n",
    "\n",
    "for category, sentences in test_sets.items():\n",
    "    print(f\"\\nüìö Category: {category}\")\n",
    "    print(\"=\" * (len(category) + 13))\n",
    "    \n",
    "    category_results = []\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        total_tests += 1\n",
    "        \n",
    "        try:\n",
    "            # Generate translation\n",
    "            translation = generate(sentence, model_large, data_dict_large, device)\n",
    "            \n",
    "            # Check if translation is reasonable (not empty, not too repetitive)\n",
    "            is_good = (\n",
    "                translation and \n",
    "                len(translation.strip()) > 0 and\n",
    "                len(translation.split()) >= 1 and\n",
    "                translation.lower() != sentence.lower()  # Not just copying input\n",
    "            )\n",
    "            \n",
    "            if is_good:\n",
    "                successful_tests += 1\n",
    "                status = \"‚úÖ\"\n",
    "            else:\n",
    "                status = \"‚ö†Ô∏è \"\n",
    "            \n",
    "            category_results.append((sentence, translation, is_good))\n",
    "            \n",
    "            print(f\"{status} '{sentence}' ‚Üí '{translation}'\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå '{sentence}' ‚Üí ERROR: {e}\")\n",
    "            category_results.append((sentence, f\"ERROR: {e}\", False))\n",
    "    \n",
    "    all_results[category] = category_results\n",
    "\n",
    "# Calculate overall success rate\n",
    "success_rate = (successful_tests / total_tests) * 100 if total_tests > 0 else 0\n",
    "\n",
    "print(f\"\\nüìä OVERALL PERFORMANCE SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"üéØ Total tests: {total_tests}\")\n",
    "print(f\"‚úÖ Successful translations: {successful_tests}\")\n",
    "print(f\"üìà Success rate: {success_rate:.1f}%\")\n",
    "print(f\"ü§ñ Model parameters: {sum(p.numel() for p in model_large.parameters()):,}\")\n",
    "\n",
    "# Category-wise performance\n",
    "print(f\"\\nüìä CATEGORY-WISE PERFORMANCE\")\n",
    "print(\"-\" * 50)\n",
    "for category, results in all_results.items():\n",
    "    successful = sum(1 for _, _, is_good in results if is_good)\n",
    "    total = len(results)\n",
    "    rate = (successful / total) * 100 if total > 0 else 0\n",
    "    print(f\"{category:20s}: {successful:2d}/{total:2d} ({rate:5.1f}%)\")\n",
    "\n",
    "# Show some impressive translations\n",
    "print(f\"\\nüåü BEST TRANSLATIONS\")\n",
    "print(\"-\" * 30)\n",
    "impressive_translations = []\n",
    "for category, results in all_results.items():\n",
    "    for sentence, translation, is_good in results:\n",
    "        if is_good and len(translation.split()) > 1:\n",
    "            impressive_translations.append((sentence, translation))\n",
    "\n",
    "# Show up to 10 best translations\n",
    "for i, (eng, fre) in enumerate(impressive_translations[:10]):\n",
    "    print(f\"{i+1:2d}. üá¨üáß {eng}\")\n",
    "    print(f\"    üá´üá∑ {fre}\")\n",
    "\n",
    "# Performance vs Training History\n",
    "print(f\"\\nüìà TRAINING EFFECTIVENESS\")\n",
    "print(\"-\" * 30)\n",
    "if len(history_large['train_acc']) > 0:\n",
    "    initial_acc = history_large['train_acc'][0]\n",
    "    final_acc = history_large['train_acc'][-1]\n",
    "    improvement = final_acc - initial_acc\n",
    "    \n",
    "    print(f\"Initial training accuracy: {initial_acc:.3f}\")\n",
    "    print(f\"Final training accuracy:   {final_acc:.3f}\")\n",
    "    print(f\"Improvement:              +{improvement:.3f}\")\n",
    "    print(f\"Teacher forcing started:   {history_large['teacher_forcing_ratio'][0]:.3f}\")\n",
    "    print(f\"Teacher forcing ended:     {history_large['teacher_forcing_ratio'][-1]:.3f}\")\n",
    "\n",
    "print(f\"\\nüéâ TESTING COMPLETED!\")\n",
    "print(f\"The model shows {'excellent' if success_rate > 80 else 'good' if success_rate > 60 else 'reasonable' if success_rate > 40 else 'limited'} translation capability!\")\n",
    "\n",
    "# Interactive testing function\n",
    "def interactive_translate(sentence):\n",
    "    \"\"\"Interactive translation function for easy testing\"\"\"\n",
    "    try:\n",
    "        translation = generate(sentence, model_large, data_dict_large, device)\n",
    "        print(f\"üá¨üáß English:  {sentence}\")\n",
    "        print(f\"üá´üá∑ French:   {translation}\")\n",
    "        return translation\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Translation error: {e}\")\n",
    "        return None\n",
    "\n",
    "print(f\"\\nüí° TIP: Use interactive_translate('your sentence') to test any English sentence!\")\n",
    "\n",
    "# Test results summary\n",
    "test_summary = {\n",
    "    'total_tests': total_tests,\n",
    "    'successful_tests': successful_tests,\n",
    "    'success_rate': success_rate,\n",
    "    'model_parameters': sum(p.numel() for p in model_large.parameters()),\n",
    "    'training_epochs': len(history_large['train_loss']),\n",
    "    'final_accuracy': history_large['train_acc'][-1] if history_large['train_acc'] else 0,\n",
    "    'category_results': all_results\n",
    "}\n",
    "\n",
    "print(f\"\\nüíæ Test results saved in 'test_summary' variable for further analysis.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.12.2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
