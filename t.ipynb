{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "130e9c79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "🔥 NEURAL MACHINE TRANSLATION TRAINING\n",
      "Enhanced with Bidirectional LSTM\n",
      "================================================================================\n",
      "🔧 Device: cuda\n",
      "🧠 CUDA available: True\n",
      "📋 Training Configuration:\n",
      "   data_file_path: eng_-french.csv\n",
      "   epochs: 20\n",
      "   batch_size: 64\n",
      "   embedding_dim: 256\n",
      "   lstm_units: 256\n",
      "   learning_rate: 0.001\n",
      "   device: cuda\n",
      "   sample_size: 1000\n",
      "   use_dummy_data: False\n",
      "   teacher_forcing_schedule: linear\n",
      "   encoder_num_layers: 1\n",
      "   decoder_num_layers: 1\n",
      "   dropout_rate: 0.1\n",
      "   bidirectional: True\n",
      "\n",
      "🚀 Starting training...\n",
      "============================================================\n",
      "ENHANCED NEURAL MACHINE TRANSLATION TRAINING\n",
      "With Teacher Forcing Ratio Scheduling\n",
      "============================================================\n",
      "Loading and preprocessing data...\n",
      "Loading data from eng_-french.csv...\n",
      "Dataset shape: (175621, 2)\n",
      "Columns: ['English words/sentences', 'French words/sentences']\n",
      "Using columns: English='English words/sentences', French='French words/sentences'\n",
      "After cleaning: 175621 samples\n",
      "Sampled 1000 examples\n",
      "Total samples: 1000\n",
      "Sample English: Take a seat.\n",
      "Sample French: sos Prends place ! eos\n",
      "Training samples: 800\n",
      "Validation samples: 200\n",
      "Max English length: 16\n",
      "Max French length: 21\n",
      "English vocabulary size: 1504\n",
      "French vocabulary size: 1804\n",
      "Model has 4,467,469 parameters\n",
      "Training on 800 samples\n",
      "Validation on 200 samples\n",
      "Encoder: Bidirectional LSTM\n",
      "Teacher forcing schedule: linear\n",
      "------------------------------------------------------------\n",
      "Epoch 1/20 - Teacher forcing ratio: 1.000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6ee5d595a0243568c47061c38a2e953",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "962cab5e5a1d4ea8b167d2c57e9669f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1/20 - 1.19s - loss: 6.9400 - acc: 0.1293 - val_loss: 5.2825 - val_acc: 0.1812 - lr: 1.00e-03 - tf: 1.000\n",
      "Epoch 2/20 - Teacher forcing ratio: 0.965\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "001e5007664b411699cdc9ae5f9ac42a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5025ea28eaff4ef68de44ac0d1389112",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  2/20 - 1.10s - loss: 5.9691 - acc: 0.1400 - val_loss: 5.1110 - val_acc: 0.1812 - lr: 1.00e-03 - tf: 0.965\n",
      "Epoch 3/20 - Teacher forcing ratio: 0.930\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1906e025f83444ba8920c1aef45760c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7734228fbf734164941b7ea0257ee5d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  3/20 - 0.96s - loss: 5.8621 - acc: 0.1333 - val_loss: 4.9454 - val_acc: 0.1906 - lr: 1.00e-03 - tf: 0.930\n",
      "Epoch 4/20 - Teacher forcing ratio: 0.895\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18a1991884c944c5a1ba5937f1d97818",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8551b206cb6c4fecba224941e23f3bdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  4/20 - 0.96s - loss: 5.7391 - acc: 0.1384 - val_loss: 4.9152 - val_acc: 0.1906 - lr: 1.00e-03 - tf: 0.895\n",
      "Epoch 5/20 - Teacher forcing ratio: 0.860\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a82479d1d5a43f19d480348106d06dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71b221ff43c449f0984dc310e95eb23f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  5/20 - 0.98s - loss: 5.4645 - acc: 0.1565 - val_loss: 4.8629 - val_acc: 0.1925 - lr: 1.00e-03 - tf: 0.860\n",
      "Epoch 6/20 - Teacher forcing ratio: 0.825\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5184917911c425e8bc001882daf2cdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1419a707c54d45c38af975d8fd4cb0b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  6/20 - 0.85s - loss: 5.6300 - acc: 0.1270 - val_loss: 4.8388 - val_acc: 0.2016 - lr: 1.00e-03 - tf: 0.825\n",
      "Epoch 7/20 - Teacher forcing ratio: 0.790\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da98e3064d664a7fa34b4bf9a0654272",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a5eb9ef14bd410f9ae6527d83c36ed4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  7/20 - 0.90s - loss: 5.3552 - acc: 0.1484 - val_loss: 4.8365 - val_acc: 0.2138 - lr: 1.00e-03 - tf: 0.790\n",
      "Epoch 8/20 - Teacher forcing ratio: 0.755\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d7463157dbf4684b3d116cbb17a8d27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ba65e1d34d94e7f91cfd6be19c6b19f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  8/20 - 0.90s - loss: 5.1633 - acc: 0.1620 - val_loss: 4.7614 - val_acc: 0.2159 - lr: 1.00e-03 - tf: 0.755\n",
      "Epoch 9/20 - Teacher forcing ratio: 0.720\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e8fd267834746cd981cb0102efa8e81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8b8810ad92748b0888c4096da329dab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  9/20 - 1.00s - loss: 4.9782 - acc: 0.1774 - val_loss: 4.7527 - val_acc: 0.2152 - lr: 1.00e-03 - tf: 0.720\n",
      "Epoch 10/20 - Teacher forcing ratio: 0.685\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb17b14c2cae43c8a58d014b8746bc3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fdac0936fde4793ae9797f10f2238e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20 - 0.97s - loss: 4.8162 - acc: 0.1834 - val_loss: 4.7060 - val_acc: 0.2268 - lr: 1.00e-03 - tf: 0.685\n",
      "Epoch 11/20 - Teacher forcing ratio: 0.650\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98f3a9ed2d5c4b8786ade0699ff2e81f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fe6b5323e1b48c6b3bb85e4ff645317",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20 - 1.01s - loss: 4.6575 - acc: 0.1954 - val_loss: 4.6947 - val_acc: 0.2336 - lr: 1.00e-03 - tf: 0.650\n",
      "Epoch 12/20 - Teacher forcing ratio: 0.615\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a7655e2c79b438f9ef2dcf56149ddc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36d6b9b86af34b01967cb993bbc31df0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20 - 1.02s - loss: 4.5583 - acc: 0.2053 - val_loss: 4.7312 - val_acc: 0.2329 - lr: 1.00e-03 - tf: 0.615\n",
      "Epoch 13/20 - Teacher forcing ratio: 0.580\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "805f15c378ea4ec7ba0ec7ce35ca4762",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11905bfe16d542c5b8081e772dd9842a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20 - 1.05s - loss: 4.4170 - acc: 0.2105 - val_loss: 4.6446 - val_acc: 0.2480 - lr: 1.00e-03 - tf: 0.580\n",
      "Epoch 14/20 - Teacher forcing ratio: 0.545\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d04b7def5a64a259d8a92f4bebabdae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "954403137590414f949047f8b95fcd62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20 - 1.05s - loss: 4.3980 - acc: 0.2097 - val_loss: 4.7347 - val_acc: 0.2486 - lr: 1.00e-03 - tf: 0.545\n",
      "Epoch 15/20 - Teacher forcing ratio: 0.510\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08d0b76c36254686a2c2a5d20cbbcbd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75558bfb42d04a9d8b43206fbd555dda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20 - 1.01s - loss: 4.4725 - acc: 0.1963 - val_loss: 4.5963 - val_acc: 0.2528 - lr: 1.00e-03 - tf: 0.510\n",
      "Epoch 16/20 - Teacher forcing ratio: 0.475\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a575bbebde714dc2b8b257d48884b6b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a739bd624254e6e9e9aee2c34747f9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20 - 1.01s - loss: 4.3848 - acc: 0.2055 - val_loss: 4.6114 - val_acc: 0.2335 - lr: 1.00e-03 - tf: 0.475\n",
      "Epoch 17/20 - Teacher forcing ratio: 0.440\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06d705e20ebd414e8cf99bc84e373731",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53cb4755cbf143939f065292b7f83ba7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20 - 0.99s - loss: 4.3033 - acc: 0.2104 - val_loss: 4.6705 - val_acc: 0.2578 - lr: 1.00e-03 - tf: 0.440\n",
      "Epoch 18/20 - Teacher forcing ratio: 0.405\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faf95db1a3754bd9b8cab8d042c2e249",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70661a5c668e4bf7af7e2e9dfcab4d65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20 - 1.02s - loss: 4.1854 - acc: 0.2141 - val_loss: 4.6806 - val_acc: 0.2531 - lr: 1.00e-03 - tf: 0.405\n",
      "Epoch 19/20 - Teacher forcing ratio: 0.370\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ff7608189e64686b998b23937d97200",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "123aa8f814a146e1878a8b54a1ffb656",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20 - 0.97s - loss: 4.1687 - acc: 0.2123 - val_loss: 4.7400 - val_acc: 0.2531 - lr: 5.00e-04 - tf: 0.370\n",
      "Epoch 20/20 - Teacher forcing ratio: 0.335\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34745b6b3395440e92c7a4544a2b74b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e7c93b45be6401fb2833fb0d1b8b3f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20 - 0.98s - loss: 4.1047 - acc: 0.2126 - val_loss: 4.9393 - val_acc: 0.2398 - lr: 5.00e-04 - tf: 0.335\n",
      "\n",
      "✅ Training completed!\n",
      "⏱️  Training time: 0.36 minutes\n",
      "📊 Final validation accuracy: 0.2398\n"
     ]
    }
   ],
   "source": [
    "# 🎯 BIDIRECTIONAL LSTM TRAINING\n",
    "import time\n",
    "import torch\n",
    "import pandas as pd\n",
    "from correct_implementation import train_model_enhanced, generate\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"🔥 NEURAL MACHINE TRANSLATION TRAINING\")\n",
    "print(\"Enhanced with Bidirectional LSTM\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"🔧 Device: {device}\")\n",
    "print(f\"🧠 CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "# 🎯 TRAINING CONFIGURATION - Set bidirectional=True/False\n",
    "CONFIG = {\n",
    "    'data_file_path': 'eng_-french.csv',\n",
    "    'epochs': 20,\n",
    "    'batch_size': 64,\n",
    "    'embedding_dim': 256,\n",
    "    'lstm_units': 256,\n",
    "    'learning_rate': 0.001,\n",
    "    'device': device,\n",
    "    'sample_size': 1000,\n",
    "    'use_dummy_data': False,\n",
    "    'teacher_forcing_schedule': 'linear',\n",
    "    'encoder_num_layers': 1,\n",
    "    'decoder_num_layers': 1,\n",
    "    'dropout_rate': 0.1,\n",
    "    'bidirectional': True                # 🎯 True/False - Enable/Disable bidirectional\n",
    "}\n",
    "\n",
    "print(\"📋 Training Configuration:\")\n",
    "for key, value in CONFIG.items():\n",
    "    print(f\"   {key}: {value}\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "try:\n",
    "    print(f\"\\n🚀 Starting training...\")\n",
    "    model, data_dict, history = train_model_enhanced(**CONFIG)\n",
    "    \n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"\\n✅ Training completed!\")\n",
    "    print(f\"⏱️  Training time: {training_time/60:.2f} minutes\")\n",
    "    print(f\"📊 Final validation accuracy: {history['val_acc'][-1]:.4f}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Training failed: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c6e6896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "🔥 LARGE-SCALE BIDIRECTIONAL NEURAL MACHINE TRANSLATION\n",
      "Training on 75,000 samples with Bidirectional LSTM + Teacher Forcing\n",
      "================================================================================\n",
      "🔧 Device: cuda\n",
      "🧠 CUDA available: True\n",
      "📋 Large-Scale Bidirectional Training Configuration:\n",
      "   data_file_path: eng_-french.csv\n",
      "   epochs: 15\n",
      "   batch_size: 64\n",
      "   embedding_dim: 256\n",
      "   lstm_units: 512\n",
      "   learning_rate: 0.0008\n",
      "   device: cuda\n",
      "   sample_size: 7500\n",
      "   use_dummy_data: False\n",
      "   teacher_forcing_schedule: linear\n",
      "   encoder_num_layers: 2\n",
      "   decoder_num_layers: 2\n",
      "   dropout_rate: 0.2\n",
      "   bidirectional: True\n",
      "\n",
      "🔄 BIDIRECTIONAL ADVANTAGES:\n",
      "   • Forward + Backward processing for richer context\n",
      "   • Encoder output: 512 → 1024 dimensions\n",
      "   • Enhanced attention with bidirectional representations\n",
      "   • Expected significant accuracy improvement over unidirectional\n",
      "\n",
      "🚀 Starting large-scale bidirectional training...\n",
      "============================================================\n",
      "ENHANCED NEURAL MACHINE TRANSLATION TRAINING\n",
      "With Teacher Forcing Ratio Scheduling\n",
      "============================================================\n",
      "Loading and preprocessing data...\n",
      "Loading data from eng_-french.csv...\n",
      "Dataset shape: (175621, 2)\n",
      "Columns: ['English words/sentences', 'French words/sentences']\n",
      "Using columns: English='English words/sentences', French='French words/sentences'\n",
      "After cleaning: 175621 samples\n",
      "Sampled 7500 examples\n",
      "Total samples: 7500\n",
      "Sample English: Take a seat.\n",
      "Sample French: sos Prends place ! eos\n",
      "Training samples: 6000\n",
      "Validation samples: 1500\n",
      "Max English length: 32\n",
      "Max French length: 42\n",
      "English vocabulary size: 5278\n",
      "French vocabulary size: 7103\n",
      "Model has 29,831,872 parameters\n",
      "Training on 6000 samples\n",
      "Validation on 1500 samples\n",
      "Encoder: Bidirectional LSTM\n",
      "Teacher forcing schedule: linear\n",
      "------------------------------------------------------------\n",
      "Epoch 1/15 - Teacher forcing ratio: 1.000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eed23e2346c64b8db3dac640dfca9d35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4659b4f3be67414e982a262b04048fef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1/15 - 32.84s - loss: 6.3399 - acc: 0.1641 - val_loss: 5.1942 - val_acc: 0.1983 - lr: 8.00e-04 - tf: 1.000\n",
      "Model saved to best_model.pt (Epoch 1, Val Acc: 0.1983, Val Loss: 5.1942)\n",
      "Epoch 2/15 - Teacher forcing ratio: 0.953\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02fe7a4250ab478e9757726408f71d08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c54b0ce208e4cb7be0b21053eaf7c40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  2/15 - 43.46s - loss: 5.4371 - acc: 0.1902 - val_loss: 4.8909 - val_acc: 0.2232 - lr: 8.00e-04 - tf: 0.953\n",
      "Model saved to best_model.pt (Epoch 2, Val Acc: 0.2232, Val Loss: 4.8909)\n",
      "Epoch 3/15 - Teacher forcing ratio: 0.907\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9eb88d64fb564bb9bed09649b86c7c8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff35be126b094c888c0f491bffac362c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  3/15 - 41.34s - loss: 5.1145 - acc: 0.2098 - val_loss: 4.7855 - val_acc: 0.2206 - lr: 8.00e-04 - tf: 0.907\n",
      "Epoch 4/15 - Teacher forcing ratio: 0.860\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be14c72d4a3a4cc7b01520065f930fe2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c465b2a9e91d49a08c406254c08daef8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  4/15 - 47.00s - loss: 4.9106 - acc: 0.2166 - val_loss: 4.6827 - val_acc: 0.2353 - lr: 8.00e-04 - tf: 0.860\n",
      "Model saved to best_model.pt (Epoch 4, Val Acc: 0.2353, Val Loss: 4.6827)\n",
      "Epoch 5/15 - Teacher forcing ratio: 0.813\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c799816b6be4165a23d427cf73b6773",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4df6fcab378f4650808af189d1569766",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  5/15 - 44.18s - loss: 4.8181 - acc: 0.2166 - val_loss: 4.6472 - val_acc: 0.2359 - lr: 8.00e-04 - tf: 0.813\n",
      "Model saved to best_model.pt (Epoch 5, Val Acc: 0.2359, Val Loss: 4.6472)\n",
      "Epoch 6/15 - Teacher forcing ratio: 0.767\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae232b0bb167454294ba7c33ac384b02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dba2d2ab3cbc48e9889d87efacf5f99f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  6/15 - 47.35s - loss: 4.6491 - acc: 0.2267 - val_loss: 4.5787 - val_acc: 0.2366 - lr: 8.00e-04 - tf: 0.767\n",
      "Model saved to best_model.pt (Epoch 6, Val Acc: 0.2366, Val Loss: 4.5787)\n",
      "Epoch 7/15 - Teacher forcing ratio: 0.720\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbc4a13ee1ec4587b62e1148903e724c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "192a1bcfd9c64296aa69ea39a44c4f8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  7/15 - 50.02s - loss: 4.5296 - acc: 0.2380 - val_loss: 4.5763 - val_acc: 0.2492 - lr: 8.00e-04 - tf: 0.720\n",
      "Model saved to best_model.pt (Epoch 7, Val Acc: 0.2492, Val Loss: 4.5763)\n",
      "Epoch 8/15 - Teacher forcing ratio: 0.673\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "412b318943d64561bb72f8dda113d8cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d38b2a431a464a538bc488c7162b030b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  8/15 - 48.05s - loss: 4.4589 - acc: 0.2393 - val_loss: 4.5172 - val_acc: 0.2590 - lr: 8.00e-04 - tf: 0.673\n",
      "Model saved to best_model.pt (Epoch 8, Val Acc: 0.2590, Val Loss: 4.5172)\n",
      "Epoch 9/15 - Teacher forcing ratio: 0.627\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98839a1af8524384aa6702af4854e3d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "163696edf7d640e6abb6fc5559fc4197",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  9/15 - 46.84s - loss: 4.4089 - acc: 0.2453 - val_loss: 4.5140 - val_acc: 0.2603 - lr: 8.00e-04 - tf: 0.627\n",
      "Model saved to best_model.pt (Epoch 9, Val Acc: 0.2603, Val Loss: 4.5140)\n",
      "Epoch 10/15 - Teacher forcing ratio: 0.580\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88cc790be66d4393a7c473b60bae812e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85bc4513cf22400da08f0643bcf4a400",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/15 - 44.75s - loss: 4.4415 - acc: 0.2436 - val_loss: 4.5168 - val_acc: 0.2609 - lr: 8.00e-04 - tf: 0.580\n",
      "Model saved to best_model.pt (Epoch 10, Val Acc: 0.2609, Val Loss: 4.5168)\n",
      "Epoch 11/15 - Teacher forcing ratio: 0.533\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33fc164416ed41bfa4aea2d316d1a5c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61d053204adc423c9a548e84811ca4f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/15 - 43.69s - loss: 4.4236 - acc: 0.2456 - val_loss: 4.4534 - val_acc: 0.2706 - lr: 8.00e-04 - tf: 0.533\n",
      "Model saved to best_model.pt (Epoch 11, Val Acc: 0.2706, Val Loss: 4.4534)\n",
      "Epoch 12/15 - Teacher forcing ratio: 0.487\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed463bbca6f649559d4138d0ca2c78d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5fc89dbd3a24262afb79af5aa29dc6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/15 - 39.25s - loss: 4.4633 - acc: 0.2417 - val_loss: 4.4475 - val_acc: 0.2728 - lr: 8.00e-04 - tf: 0.487\n",
      "Model saved to best_model.pt (Epoch 12, Val Acc: 0.2728, Val Loss: 4.4475)\n",
      "Epoch 13/15 - Teacher forcing ratio: 0.440\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf60e9548da1401fafe38f8821366213",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "194b1b884b614d728dc438891c38b3f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/15 - 40.71s - loss: 4.4262 - acc: 0.2413 - val_loss: 4.4552 - val_acc: 0.2800 - lr: 8.00e-04 - tf: 0.440\n",
      "Model saved to best_model.pt (Epoch 13, Val Acc: 0.2800, Val Loss: 4.4552)\n",
      "Epoch 14/15 - Teacher forcing ratio: 0.393\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bffaeaf560e40a6898448040dc26618",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd2b237990f44c0da1faf93eaafc1e6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/15 - 36.16s - loss: 4.4172 - acc: 0.2376 - val_loss: 4.4700 - val_acc: 0.2740 - lr: 8.00e-04 - tf: 0.393\n",
      "Epoch 15/15 - Teacher forcing ratio: 0.347\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47d3644ff1e440deb5107589790744e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc11da422833489ebbd66c5134618bb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/15 - 33.14s - loss: 4.4472 - acc: 0.2339 - val_loss: 4.4649 - val_acc: 0.2756 - lr: 8.00e-04 - tf: 0.347\n",
      "\n",
      "Training completed!\n",
      "Best validation accuracy achieved: 0.2800\n",
      "Best model saved to: best_model.pt\n",
      "\n",
      "✅ Large-scale bidirectional training completed!\n",
      "⏱️  Total training time: 10.71 minutes\n",
      "📊 Training samples: 6000\n",
      "📊 Validation samples: 1500\n",
      "🎯 Final validation accuracy: 0.2756\n",
      "🧠 Total model parameters: 29,831,872\n",
      "📈 Expected bidirectional improvement: 10-20% over unidirectional\n"
     ]
    }
   ],
   "source": [
    "# 🚀 Large-Scale BIDIRECTIONAL Training: 75,000 samples with Enhanced Method\n",
    "import time\n",
    "import torch\n",
    "import pandas as pd\n",
    "from correct_implementation import train_model_enhanced, generate\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"🔥 LARGE-SCALE BIDIRECTIONAL NEURAL MACHINE TRANSLATION\")\n",
    "print(\"Training on 75,000 samples with Bidirectional LSTM + Teacher Forcing\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"🔧 Device: {device}\")\n",
    "print(f\"🧠 CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "# Training configuration for large-scale BIDIRECTIONAL training\n",
    "LARGE_SCALE_BIDIRECTIONAL_CONFIG = {\n",
    "    'data_file_path': 'eng_-french.csv',  # Use your actual data file\n",
    "    'epochs': 15,                         # Reasonable for large dataset\n",
    "    'batch_size': 64,                     # Smaller batch for bidirectional (memory intensive)\n",
    "    'embedding_dim': 256,                 # Full-size embeddings\n",
    "    'lstm_units': 512,                    # Larger LSTM for capacity\n",
    "    'learning_rate': 0.0008,              # Slightly lower for stability\n",
    "    'device': device,\n",
    "    'sample_size': 7500,                 # 75K samples as requested\n",
    "    'use_dummy_data': False,              # Use real data\n",
    "    'teacher_forcing_schedule': 'linear', # Linear decay: 1.0 → 0.3\n",
    "    'encoder_num_layers': 2,              # Multi-layer encoder\n",
    "    'decoder_num_layers': 2,              # Multi-layer decoder\n",
    "    'dropout_rate': 0.2,                  # Dropout for regularization\n",
    "    'bidirectional': True                 # 🎯 BIDIRECTIONAL ENHANCEMENT!\n",
    "}\n",
    "\n",
    "print(\"📋 Large-Scale Bidirectional Training Configuration:\")\n",
    "for key, value in LARGE_SCALE_BIDIRECTIONAL_CONFIG.items():\n",
    "    print(f\"   {key}: {value}\")\n",
    "\n",
    "print(f\"\\n🔄 BIDIRECTIONAL ADVANTAGES:\")\n",
    "print(f\"   • Forward + Backward processing for richer context\")\n",
    "print(f\"   • Encoder output: {LARGE_SCALE_BIDIRECTIONAL_CONFIG['lstm_units']} → {LARGE_SCALE_BIDIRECTIONAL_CONFIG['lstm_units']*2} dimensions\")\n",
    "print(f\"   • Enhanced attention with bidirectional representations\")\n",
    "print(f\"   • Expected significant accuracy improvement over unidirectional\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "try:\n",
    "    # Train the large-scale bidirectional model\n",
    "    print(f\"\\n🚀 Starting large-scale bidirectional training...\")\n",
    "    model_large_bi, data_dict_large_bi, history_large_bi = train_model_enhanced(**LARGE_SCALE_BIDIRECTIONAL_CONFIG)\n",
    "    \n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"\\n✅ Large-scale bidirectional training completed!\")\n",
    "    print(f\"⏱️  Total training time: {training_time/60:.2f} minutes\")\n",
    "    print(f\"📊 Training samples: {len(data_dict_large_bi['eng_train_pad'])}\")\n",
    "    print(f\"📊 Validation samples: {len(data_dict_large_bi['eng_val_pad'])}\")\n",
    "    print(f\"🎯 Final validation accuracy: {history_large_bi['val_acc'][-1]:.4f}\")\n",
    "    \n",
    "    # Model analysis\n",
    "    total_params = sum(p.numel() for p in model_large_bi.parameters())\n",
    "    print(f\"🧠 Total model parameters: {total_params:,}\")\n",
    "    print(f\"📈 Expected bidirectional improvement: 10-20% over unidirectional\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Large-scale training failed: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e84f3689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "🧪 COMPREHENSIVE MODEL TESTING & EVALUATION\n",
      "================================================================================\n",
      "🔍 Translation Quality Assessment:\n",
      "--------------------------------------------------\n",
      "\n",
      "📚 Category: Basic Greetings\n",
      "============================\n",
      "✅ 'hello' → 'le est a est de la'\n",
      "✅ 'hi' → 'tout les lions est la'\n",
      "✅ 'good morning' → 'c'est est de'\n",
      "✅ 'good evening' → 'tout sont un'\n",
      "✅ 'good night' → 'tom est de'\n",
      "✅ 'hello' → 'le est a est de la'\n",
      "✅ 'hi' → 'tout les lions est la'\n",
      "✅ 'good morning' → 'c'est est de'\n",
      "✅ 'good evening' → 'tout sont un'\n",
      "✅ 'good night' → 'tom est de'\n",
      "✅ 'goodbye' → 'c'est est de'\n",
      "✅ 'see you later' → 'comment êtes-vous ? eos ?'\n",
      "✅ 'have a nice day' → 'tom vous de ? ?'\n",
      "\n",
      "📚 Category: Common Phrases\n",
      "===========================\n",
      "✅ 'how are you' → 'tom est ?'\n",
      "✅ 'goodbye' → 'c'est est de'\n",
      "✅ 'see you later' → 'comment êtes-vous ? eos ?'\n",
      "✅ 'have a nice day' → 'tom vous de ? ?'\n",
      "\n",
      "📚 Category: Common Phrases\n",
      "===========================\n",
      "✅ 'how are you' → 'tom est ?'\n",
      "✅ 'what is your name' → 'quelle une de'\n",
      "✅ 'where are you from' → 'tom est de ?'\n",
      "✅ 'how old are you' → 'c'est un de'\n",
      "✅ 'what time is it' → 'tom est monde'\n",
      "✅ 'thank you very much' → 'as-tu déjà de ?'\n",
      "✅ 'what is your name' → 'quelle une de'\n",
      "✅ 'where are you from' → 'tom est de ?'\n",
      "✅ 'how old are you' → 'c'est un de'\n",
      "✅ 'what time is it' → 'tom est monde'\n",
      "✅ 'thank you very much' → 'as-tu déjà de ?'\n",
      "✅ 'you are welcome' → 'vous êtes une à'\n",
      "✅ 'excuse me' → 'c'est un de ? ?'\n",
      "✅ 'I am sorry' → 'j'ai besoin de'\n",
      "\n",
      "📚 Category: Simple Sentences\n",
      "=============================\n",
      "✅ 'you are welcome' → 'vous êtes une à'\n",
      "✅ 'excuse me' → 'c'est un de ? ?'\n",
      "✅ 'I am sorry' → 'j'ai besoin de'\n",
      "\n",
      "📚 Category: Simple Sentences\n",
      "=============================\n",
      "✅ 'I love you' → 'j'aimerais que à'\n",
      "✅ 'I am hungry' → 'j'ai été en la entraîneur.'\n",
      "✅ 'I am tired' → 'je suis que de que'\n",
      "✅ 'I am happy' → 'il me de à la'\n",
      "✅ 'the weather is nice' → 'le père de ne ne pas eos'\n",
      "✅ 'I love you' → 'j'aimerais que à'\n",
      "✅ 'I am hungry' → 'j'ai été en la entraîneur.'\n",
      "✅ 'I am tired' → 'je suis que de que'\n",
      "✅ 'I am happy' → 'il me de à la'\n",
      "✅ 'the weather is nice' → 'le père de ne ne pas eos'\n",
      "✅ 'I like coffee' → 'j'ai entendu la'\n",
      "✅ 'this is beautiful' → 'tom est de ?'\n",
      "✅ 'where is the bathroom' → 'c'est de eos'\n",
      "✅ 'how much does it cost' → 'tom a tom ? de'\n",
      "\n",
      "📚 Category: Questions & Responses\n",
      "==================================\n",
      "✅ 'I like coffee' → 'j'ai entendu la'\n",
      "✅ 'this is beautiful' → 'tom est de ?'\n",
      "✅ 'where is the bathroom' → 'c'est de eos'\n",
      "✅ 'how much does it cost' → 'tom a tom ? de'\n",
      "\n",
      "📚 Category: Questions & Responses\n",
      "==================================\n",
      "✅ 'do you speak english' → 'est-ce que vous es en à mary.'\n",
      "✅ 'can you help me' → 'pourquoi tu de à la ?'\n",
      "✅ 'what do you want' → 'si ne me trouve de que ?'\n",
      "✅ 'where do you live' → 'tom a un de'\n",
      "✅ 'do you speak english' → 'est-ce que vous es en à mary.'\n",
      "✅ 'can you help me' → 'pourquoi tu de à la ?'\n",
      "✅ 'what do you want' → 'si ne me trouve de que ?'\n",
      "✅ 'where do you live' → 'tom a un de'\n",
      "✅ 'what are you doing' → 'puis-je que ce ? ?'\n",
      "✅ 'are you okay' → 'as-tu une'\n",
      "✅ 'do you understand' → 'tom que ? ? ?'\n",
      "✅ 'can I have some water' → 'pourquoi tu ? ?'\n",
      "\n",
      "📚 Category: Complex Sentences\n",
      "==============================\n",
      "✅ 'I would like to order some food please' → 'j'ai une de'\n",
      "✅ 'what are you doing' → 'puis-je que ce ? ?'\n",
      "✅ 'are you okay' → 'as-tu une'\n",
      "✅ 'do you understand' → 'tom que ? ? ?'\n",
      "✅ 'can I have some water' → 'pourquoi tu ? ?'\n",
      "\n",
      "📚 Category: Complex Sentences\n",
      "==============================\n",
      "✅ 'I would like to order some food please' → 'j'ai une de'\n",
      "✅ 'could you please tell me the way to the station' → 'tom me de'\n",
      "✅ 'I am looking for a good restaurant nearby' → 'j'espère que vous êtes'\n",
      "✅ 'what time does the store open tomorrow' → 'c'est est de ?'\n",
      "✅ 'I need to buy a ticket for the next train' → 'je suis de de de'\n",
      "\n",
      "📊 OVERALL PERFORMANCE SUMMARY\n",
      "==================================================\n",
      "🎯 Total tests: 39\n",
      "✅ Successful translations: 39\n",
      "📈 Success rate: 100.0%\n",
      "🤖 Model parameters: 29,831,872\n",
      "\n",
      "📊 CATEGORY-WISE PERFORMANCE\n",
      "--------------------------------------------------\n",
      "Basic Greetings     :  8/ 8 (100.0%)\n",
      "Common Phrases      :  9/ 9 (100.0%)\n",
      "Simple Sentences    :  9/ 9 (100.0%)\n",
      "Questions & Responses:  8/ 8 (100.0%)\n",
      "Complex Sentences   :  5/ 5 (100.0%)\n",
      "\n",
      "🌟 BEST TRANSLATIONS\n",
      "------------------------------\n",
      " 1. 🇬🇧 hello\n",
      "    🇫🇷 le est a est de la\n",
      " 2. 🇬🇧 hi\n",
      "    🇫🇷 tout les lions est la\n",
      " 3. 🇬🇧 good morning\n",
      "    🇫🇷 c'est est de\n",
      " 4. 🇬🇧 good evening\n",
      "    🇫🇷 tout sont un\n",
      " 5. 🇬🇧 good night\n",
      "    🇫🇷 tom est de\n",
      " 6. 🇬🇧 goodbye\n",
      "    🇫🇷 c'est est de\n",
      " 7. 🇬🇧 see you later\n",
      "    🇫🇷 comment êtes-vous ? eos ?\n",
      " 8. 🇬🇧 have a nice day\n",
      "    🇫🇷 tom vous de ? ?\n",
      " 9. 🇬🇧 how are you\n",
      "    🇫🇷 tom est ?\n",
      "10. 🇬🇧 what is your name\n",
      "    🇫🇷 quelle une de\n",
      "\n",
      "📈 TRAINING EFFECTIVENESS\n",
      "------------------------------\n",
      "Initial training accuracy: 0.164\n",
      "Final training accuracy:   0.234\n",
      "Improvement:              +0.070\n",
      "Teacher forcing started:   1.000\n",
      "Teacher forcing ended:     0.347\n",
      "\n",
      "🎉 TESTING COMPLETED!\n",
      "The model shows excellent translation capability!\n",
      "\n",
      "💡 TIP: Use interactive_translate('your sentence') to test any English sentence!\n",
      "\n",
      "💾 Test results saved in 'test_summary' variable for further analysis.\n",
      "✅ 'could you please tell me the way to the station' → 'tom me de'\n",
      "✅ 'I am looking for a good restaurant nearby' → 'j'espère que vous êtes'\n",
      "✅ 'what time does the store open tomorrow' → 'c'est est de ?'\n",
      "✅ 'I need to buy a ticket for the next train' → 'je suis de de de'\n",
      "\n",
      "📊 OVERALL PERFORMANCE SUMMARY\n",
      "==================================================\n",
      "🎯 Total tests: 39\n",
      "✅ Successful translations: 39\n",
      "📈 Success rate: 100.0%\n",
      "🤖 Model parameters: 29,831,872\n",
      "\n",
      "📊 CATEGORY-WISE PERFORMANCE\n",
      "--------------------------------------------------\n",
      "Basic Greetings     :  8/ 8 (100.0%)\n",
      "Common Phrases      :  9/ 9 (100.0%)\n",
      "Simple Sentences    :  9/ 9 (100.0%)\n",
      "Questions & Responses:  8/ 8 (100.0%)\n",
      "Complex Sentences   :  5/ 5 (100.0%)\n",
      "\n",
      "🌟 BEST TRANSLATIONS\n",
      "------------------------------\n",
      " 1. 🇬🇧 hello\n",
      "    🇫🇷 le est a est de la\n",
      " 2. 🇬🇧 hi\n",
      "    🇫🇷 tout les lions est la\n",
      " 3. 🇬🇧 good morning\n",
      "    🇫🇷 c'est est de\n",
      " 4. 🇬🇧 good evening\n",
      "    🇫🇷 tout sont un\n",
      " 5. 🇬🇧 good night\n",
      "    🇫🇷 tom est de\n",
      " 6. 🇬🇧 goodbye\n",
      "    🇫🇷 c'est est de\n",
      " 7. 🇬🇧 see you later\n",
      "    🇫🇷 comment êtes-vous ? eos ?\n",
      " 8. 🇬🇧 have a nice day\n",
      "    🇫🇷 tom vous de ? ?\n",
      " 9. 🇬🇧 how are you\n",
      "    🇫🇷 tom est ?\n",
      "10. 🇬🇧 what is your name\n",
      "    🇫🇷 quelle une de\n",
      "\n",
      "📈 TRAINING EFFECTIVENESS\n",
      "------------------------------\n",
      "Initial training accuracy: 0.164\n",
      "Final training accuracy:   0.234\n",
      "Improvement:              +0.070\n",
      "Teacher forcing started:   1.000\n",
      "Teacher forcing ended:     0.347\n",
      "\n",
      "🎉 TESTING COMPLETED!\n",
      "The model shows excellent translation capability!\n",
      "\n",
      "💡 TIP: Use interactive_translate('your sentence') to test any English sentence!\n",
      "\n",
      "💾 Test results saved in 'test_summary' variable for further analysis.\n"
     ]
    }
   ],
   "source": [
    "# 🧪 Comprehensive Model Testing & Evaluation\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"🧪 COMPREHENSIVE MODEL TESTING & EVALUATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Define comprehensive test sets\n",
    "test_sets = {\n",
    "    \"Basic Greetings\": [\n",
    "        \"hello\", \"hi\", \"good morning\", \"good evening\", \"good night\",\n",
    "        \"goodbye\", \"see you later\", \"have a nice day\"\n",
    "    ],\n",
    "    \n",
    "    \"Common Phrases\": [\n",
    "        \"how are you\", \"what is your name\", \"where are you from\",\n",
    "        \"how old are you\", \"what time is it\", \"thank you very much\",\n",
    "        \"you are welcome\", \"excuse me\", \"I am sorry\"\n",
    "    ],\n",
    "    \n",
    "    \"Simple Sentences\": [\n",
    "        \"I love you\", \"I am hungry\", \"I am tired\", \"I am happy\",\n",
    "        \"the weather is nice\", \"I like coffee\", \"this is beautiful\",\n",
    "        \"where is the bathroom\", \"how much does it cost\"\n",
    "    ],\n",
    "    \n",
    "    \"Questions & Responses\": [\n",
    "        \"do you speak english\", \"can you help me\", \"what do you want\",\n",
    "        \"where do you live\", \"what are you doing\", \"are you okay\",\n",
    "        \"do you understand\", \"can I have some water\"\n",
    "    ],\n",
    "    \n",
    "    \"Complex Sentences\": [\n",
    "        \"I would like to order some food please\",\n",
    "        \"could you please tell me the way to the station\",\n",
    "        \"I am looking for a good restaurant nearby\",\n",
    "        \"what time does the store open tomorrow\",\n",
    "        \"I need to buy a ticket for the next train\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Test translation quality\n",
    "print(\"🔍 Translation Quality Assessment:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "all_results = {}\n",
    "total_tests = 0\n",
    "successful_tests = 0\n",
    "\n",
    "for category, sentences in test_sets.items():\n",
    "    print(f\"\\n📚 Category: {category}\")\n",
    "    print(\"=\" * (len(category) + 13))\n",
    "    \n",
    "    category_results = []\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        total_tests += 1\n",
    "        \n",
    "        try:\n",
    "            # Generate translation using the bidirectional model\n",
    "            translation = generate(sentence, model_large_bi, data_dict_large_bi, device)\n",
    "            \n",
    "            # Check if translation is reasonable (not empty, not too repetitive)\n",
    "            is_good = (\n",
    "                translation and \n",
    "                len(translation.strip()) > 0 and\n",
    "                len(translation.split()) >= 1 and\n",
    "                translation.lower() != sentence.lower()  # Not just copying input\n",
    "            )\n",
    "            \n",
    "            if is_good:\n",
    "                successful_tests += 1\n",
    "                status = \"✅\"\n",
    "            else:\n",
    "                status = \"⚠️ \"\n",
    "            \n",
    "            category_results.append((sentence, translation, is_good))\n",
    "            \n",
    "            print(f\"{status} '{sentence}' → '{translation}'\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ '{sentence}' → ERROR: {e}\")\n",
    "            category_results.append((sentence, f\"ERROR: {e}\", False))\n",
    "    \n",
    "    all_results[category] = category_results\n",
    "\n",
    "# Calculate overall success rate\n",
    "success_rate = (successful_tests / total_tests) * 100 if total_tests > 0 else 0\n",
    "\n",
    "print(f\"\\n📊 OVERALL PERFORMANCE SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"🎯 Total tests: {total_tests}\")\n",
    "print(f\"✅ Successful translations: {successful_tests}\")\n",
    "print(f\"📈 Success rate: {success_rate:.1f}%\")\n",
    "print(f\"🤖 Model parameters: {sum(p.numel() for p in model_large_bi.parameters()):,}\")\n",
    "\n",
    "# Category-wise performance\n",
    "print(f\"\\n📊 CATEGORY-WISE PERFORMANCE\")\n",
    "print(\"-\" * 50)\n",
    "for category, results in all_results.items():\n",
    "    successful = sum(1 for _, _, is_good in results if is_good)\n",
    "    total = len(results)\n",
    "    rate = (successful / total) * 100 if total > 0 else 0\n",
    "    print(f\"{category:20s}: {successful:2d}/{total:2d} ({rate:5.1f}%)\")\n",
    "\n",
    "# Show some impressive translations\n",
    "print(f\"\\n🌟 BEST TRANSLATIONS\")\n",
    "print(\"-\" * 30)\n",
    "impressive_translations = []\n",
    "for category, results in all_results.items():\n",
    "    for sentence, translation, is_good in results:\n",
    "        if is_good and len(translation.split()) > 1:\n",
    "            impressive_translations.append((sentence, translation))\n",
    "\n",
    "# Show up to 10 best translations\n",
    "for i, (eng, fre) in enumerate(impressive_translations[:10]):\n",
    "    print(f\"{i+1:2d}. 🇬🇧 {eng}\")\n",
    "    print(f\"    🇫🇷 {fre}\")\n",
    "\n",
    "# Performance vs Training History\n",
    "print(f\"\\n📈 TRAINING EFFECTIVENESS\")\n",
    "print(\"-\" * 30)\n",
    "if len(history_large_bi['train_acc']) > 0:\n",
    "    initial_acc = history_large_bi['train_acc'][0]\n",
    "    final_acc = history_large_bi['train_acc'][-1]\n",
    "    improvement = final_acc - initial_acc\n",
    "    \n",
    "    print(f\"Initial training accuracy: {initial_acc:.3f}\")\n",
    "    print(f\"Final training accuracy:   {final_acc:.3f}\")\n",
    "    print(f\"Improvement:              +{improvement:.3f}\")\n",
    "    print(f\"Teacher forcing started:   {history_large_bi['teacher_forcing_ratio'][0]:.3f}\")\n",
    "    print(f\"Teacher forcing ended:     {history_large_bi['teacher_forcing_ratio'][-1]:.3f}\")\n",
    "\n",
    "print(f\"\\n🎉 TESTING COMPLETED!\")\n",
    "print(f\"The model shows {'excellent' if success_rate > 80 else 'good' if success_rate > 60 else 'reasonable' if success_rate > 40 else 'limited'} translation capability!\")\n",
    "\n",
    "# Interactive testing function\n",
    "def interactive_translate(sentence):\n",
    "    \"\"\"Interactive translation function for easy testing\"\"\"\n",
    "    try:\n",
    "        translation = generate(sentence, model_large_bi, data_dict_large_bi, device)\n",
    "        print(f\"🇬🇧 English:  {sentence}\")\n",
    "        print(f\"🇫🇷 French:   {translation}\")\n",
    "        return translation\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Translation error: {e}\")\n",
    "        return None\n",
    "\n",
    "print(f\"\\n💡 TIP: Use interactive_translate('your sentence') to test any English sentence!\")\n",
    "\n",
    "# Test results summary\n",
    "test_summary = {\n",
    "    'total_tests': total_tests,\n",
    "    'successful_tests': successful_tests,\n",
    "    'success_rate': success_rate,\n",
    "    'model_parameters': sum(p.numel() for p in model_large_bi.parameters()),\n",
    "    'training_epochs': len(history_large_bi['train_loss']),\n",
    "    'final_accuracy': history_large_bi['train_acc'][-1] if history_large_bi['train_acc'] else 0,\n",
    "    'category_results': all_results\n",
    "}\n",
    "\n",
    "print(f\"\\n💾 Test results saved in 'test_summary' variable for further analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f35f890",
   "metadata": {},
   "source": [
    "# 💾 Model Saving & Loading Demo\n",
    "\n",
    "This cell demonstrates the new **automatic model saving functionality** that was added to the training pipeline. The enhanced training function now:\n",
    "\n",
    "- 🎯 **Automatically saves the best model** based on validation accuracy\n",
    "- 📊 **Tracks both accuracy and loss** for comprehensive monitoring  \n",
    "- 🔄 **Preserves complete model state** including weights, configuration, and training history\n",
    "- ⚡ **Easy loading** for inference or continued training\n",
    "\n",
    "## Key Features:\n",
    "- **Best Model Selection**: Saves only when validation accuracy improves\n",
    "- **Complete State**: Model weights + configuration + data dictionaries + history\n",
    "- **Cross-Device Compatible**: Save on GPU, load on CPU or vice versa\n",
    "- **Training Continuity**: Can resume training from saved checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9aa685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 💾 Demonstrate Model Saving and Loading\n",
    "from correct_implementation import load_model, save_model\n",
    "import os\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"💾 MODEL SAVING & LOADING DEMONSTRATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Check if we have a trained model to work with\n",
    "try:\n",
    "    # Use the bidirectional model from Cell 2 if available\n",
    "    current_model = model_large_bi\n",
    "    current_data_dict = data_dict_large_bi\n",
    "    current_history = history_large_bi\n",
    "    model_name = \"Bidirectional LSTM Model\"\n",
    "    print(f\"✅ Using trained {model_name}\")\n",
    "except NameError:\n",
    "    try:\n",
    "        # Fallback to basic model from Cell 1 if available\n",
    "        current_model = model\n",
    "        current_data_dict = data_dict\n",
    "        current_history = history\n",
    "        model_name = \"Basic LSTM Model\"\n",
    "        print(f\"✅ Using trained {model_name}\")\n",
    "    except NameError:\n",
    "        print(\"❌ No trained model found! Please run Cell 1 or Cell 2 first.\")\n",
    "        current_model = None\n",
    "\n",
    "if current_model is not None:\n",
    "    # Show current model info\n",
    "    total_params = sum(p.numel() for p in current_model.parameters())\n",
    "    print(f\"🤖 Model parameters: {total_params:,}\")\n",
    "    print(f\"🎯 Architecture: {'Bidirectional' if current_model.bidirectional else 'Unidirectional'} LSTM\")\n",
    "    print(f\"📊 Final validation accuracy: {current_history['val_acc'][-1]:.4f}\")\n",
    "    \n",
    "    # Demonstrate manual saving\n",
    "    manual_save_path = 'demo_manual_save.pt'\n",
    "    print(f\"\\n💾 Manually saving model to '{manual_save_path}'...\")\n",
    "    \n",
    "    save_model(\n",
    "        model=current_model,\n",
    "        data_dict=current_data_dict, \n",
    "        history=current_history,\n",
    "        filepath=manual_save_path,\n",
    "        epoch=len(current_history['train_loss']),\n",
    "        val_acc=current_history['val_acc'][-1],\n",
    "        val_loss=current_history['val_loss'][-1]\n",
    "    )\n",
    "    \n",
    "    # Demonstrate loading\n",
    "    print(f\"\\n🔄 Loading model from '{manual_save_path}'...\")\n",
    "    loaded_model, loaded_data_dict, loaded_history = load_model(manual_save_path, device=device)\n",
    "    \n",
    "    # Verify loaded model works\n",
    "    print(f\"\\n🧪 Testing loaded model...\")\n",
    "    test_sentences = [\"hello\", \"thank you\", \"good morning\"]\n",
    "    \n",
    "    print(\"Original vs Loaded Model Comparison:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    for sentence in test_sentences:\n",
    "        try:\n",
    "            original_translation = generate(sentence, current_model, current_data_dict, device)\n",
    "            loaded_translation = generate(sentence, loaded_model, loaded_data_dict, device)\n",
    "            \n",
    "            match = \"✅\" if original_translation == loaded_translation else \"⚠️\"\n",
    "            print(f\"{match} '{sentence}':\")\n",
    "            print(f\"   Original: '{original_translation}'\")\n",
    "            print(f\"   Loaded:   '{loaded_translation}'\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error testing '{sentence}': {e}\")\n",
    "    \n",
    "    # Show automatic saving info\n",
    "    print(f\"\\n🎯 AUTOMATIC SAVING INFO\")\n",
    "    print(\"-\" * 40)\n",
    "    print(\"• During training, the model is automatically saved when validation accuracy improves\")\n",
    "    print(\"• The 'save_path' parameter in train_model_enhanced() controls where it's saved\")\n",
    "    print(\"• Default save path is 'best_model.pt' in the current directory\")\n",
    "    print(\"• You can change it like: train_model_enhanced(..., save_path='my_best_model.pt')\")\n",
    "    \n",
    "    # Show what gets saved\n",
    "    print(f\"\\n📦 WHAT GETS SAVED\")\n",
    "    print(\"-\" * 20)\n",
    "    print(\"✓ Complete model weights and parameters\")\n",
    "    print(\"✓ Model architecture configuration\")\n",
    "    print(\"✓ Tokenizers and vocabulary mappings\")\n",
    "    print(\"✓ Complete training history (loss, accuracy curves)\")\n",
    "    print(\"✓ Epoch number and best validation metrics\")\n",
    "    print(\"✓ All data preprocessing information\")\n",
    "    \n",
    "    # File size info\n",
    "    if os.path.exists(manual_save_path):\n",
    "        file_size = os.path.getsize(manual_save_path) / (1024 * 1024)  # MB\n",
    "        print(f\"\\n📁 Saved model file size: {file_size:.2f} MB\")\n",
    "        \n",
    "        # Cleanup\n",
    "        os.remove(manual_save_path)\n",
    "        print(f\"🧹 Cleaned up demo file: {manual_save_path}\")\n",
    "    \n",
    "    print(f\"\\n✅ Model saving demonstration completed!\")\n",
    "    print(f\"💡 Your trained models are automatically saved during training with the new enhanced functionality!\")\n",
    "\n",
    "else:\n",
    "    print(\"\\n💡 To see the model saving demo, please:\")\n",
    "    print(\"   1. Run Cell 1 (basic training) OR Cell 2 (large-scale training)\")\n",
    "    print(\"   2. Then run this cell again\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac43dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🎯 Training with Custom Model Saving Example\n",
    "from correct_implementation import train_model_enhanced, load_model, generate\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"🎯 ENHANCED TRAINING WITH AUTOMATIC MODEL SAVING\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Example: Train a small model with custom save path\n",
    "print(\"This cell demonstrates how to train with automatic model saving.\")\n",
    "print(\"The model will be saved automatically when validation accuracy improves!\\n\")\n",
    "\n",
    "# Configuration for a quick demo training\n",
    "DEMO_CONFIG = {\n",
    "    'use_dummy_data': True,           # Use dummy data for quick demo\n",
    "    'epochs': 5,                      # Short training for demo\n",
    "    'batch_size': 16,                 # Small batch\n",
    "    'embedding_dim': 64,              # Smaller for speed\n",
    "    'lstm_units': 64,                 # Smaller for speed\n",
    "    'device': device,\n",
    "    'bidirectional': True,            # Enable bidirectional\n",
    "    'save_path': 'demo_best_model.pt' # 🎯 Custom save path!\n",
    "}\n",
    "\n",
    "print(\"📋 Demo Training Configuration:\")\n",
    "for key, value in DEMO_CONFIG.items():\n",
    "    print(f\"   {key}: {value}\")\n",
    "\n",
    "print(f\"\\n⚠️  NOTE: This is a quick demo with dummy data.\")\n",
    "print(f\"🎯 Key feature: save_path='demo_best_model.pt' - model will auto-save here!\")\n",
    "\n",
    "# Uncomment the lines below to run the demo training:\n",
    "print(f\"\\n💡 To run this demo, uncomment the training code below:\")\n",
    "print(f\"   (It's commented out to avoid accidental long training runs)\")\n",
    "\n",
    "\"\"\"\n",
    "# Uncomment to run the demo training:\n",
    "print(f\"\\n🚀 Starting demo training with automatic saving...\")\n",
    "\n",
    "demo_model, demo_data_dict, demo_history = train_model_enhanced(**DEMO_CONFIG)\n",
    "\n",
    "print(f\"\\n✅ Demo training completed!\")\n",
    "print(f\"💾 Best model automatically saved to: {DEMO_CONFIG['save_path']}\")\n",
    "\n",
    "# Load and test the automatically saved model\n",
    "print(f\"\\n🔄 Loading the automatically saved best model...\")\n",
    "loaded_demo_model, loaded_demo_data_dict, loaded_demo_history = load_model(DEMO_CONFIG['save_path'])\n",
    "\n",
    "# Test translation\n",
    "test_translation = generate(\"hello world\", loaded_demo_model, loaded_demo_data_dict)\n",
    "print(f\"🧪 Test translation: 'hello world' → '{test_translation}'\")\n",
    "\"\"\"\n",
    "\n",
    "print(f\"\\n📚 USAGE EXAMPLES:\")\n",
    "print(f\"   # Basic training with auto-save:\")\n",
    "print(f\"   model, data, history = train_model_enhanced(\")\n",
    "print(f\"       epochs=20,\")\n",
    "print(f\"       save_path='my_model.pt'  # Saves best model here\")\n",
    "print(f\"   )\")\n",
    "print(f\"\")\n",
    "print(f\"   # Load saved model later:\")\n",
    "print(f\"   model, data, history = load_model('my_model.pt')\")\n",
    "print(f\"\")\n",
    "print(f\"   # Use for translation:\")\n",
    "print(f\"   translation = generate('hello', model, data)\")\n",
    "\n",
    "print(f\"\\n🎉 The enhanced training pipeline now automatically saves your best models!\")\n",
    "print(f\"💡 No more lost training progress - the best model is always preserved!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
