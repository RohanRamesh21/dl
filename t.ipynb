{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c6e6896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "🔥 LARGE-SCALE NEURAL MACHINE TRANSLATION TRAINING\n",
      "Training on 75,000 samples with Teacher Forcing Ratio Scheduling\n",
      "================================================================================\n",
      "🔧 Device: cuda\n",
      "🧠 CUDA available: True\n",
      "📋 Training Configuration:\n",
      "   data_file_path: eng_-french.csv\n",
      "   epochs: 25\n",
      "   batch_size: 128\n",
      "   embedding_dim: 256\n",
      "   lstm_units: 512\n",
      "   learning_rate: 0.0008\n",
      "   device: cuda\n",
      "   sample_size: 75000\n",
      "   use_dummy_data: False\n",
      "   teacher_forcing_schedule: linear\n",
      "\n",
      "🚀 Starting large-scale training...\n",
      "============================================================\n",
      "ENHANCED NEURAL MACHINE TRANSLATION TRAINING\n",
      "With Teacher Forcing Ratio Scheduling\n",
      "============================================================\n",
      "Loading and preprocessing data...\n",
      "Loading data from eng_-french.csv...\n",
      "Dataset shape: (175621, 2)\n",
      "Columns: ['English words/sentences', 'French words/sentences']\n",
      "Using columns: English='English words/sentences', French='French words/sentences'\n",
      "After cleaning: 175621 samples\n",
      "Sampled 75000 examples\n",
      "Total samples: 75000\n",
      "Sample English: Take a seat.\n",
      "Sample French: sos Prends place ! eos\n",
      "Training samples: 60000\n",
      "Validation samples: 15000\n",
      "Dataset shape: (175621, 2)\n",
      "Columns: ['English words/sentences', 'French words/sentences']\n",
      "Using columns: English='English words/sentences', French='French words/sentences'\n",
      "After cleaning: 175621 samples\n",
      "Sampled 75000 examples\n",
      "Total samples: 75000\n",
      "Sample English: Take a seat.\n",
      "Sample French: sos Prends place ! eos\n",
      "Training samples: 60000\n",
      "Validation samples: 15000\n",
      "Max English length: 35\n",
      "Max French length: 42\n",
      "Max English length: 35\n",
      "Max French length: 42\n",
      "English vocabulary size: 16729\n",
      "French vocabulary size: 25957\n",
      "English vocabulary size: 16729\n",
      "French vocabulary size: 25957\n",
      "Model has 40,683,365 parameters\n",
      "Training on 60000 samples\n",
      "Validation on 15000 samples\n",
      "Teacher forcing schedule: linear\n",
      "------------------------------------------------------------\n",
      "Epoch 1/25 - Teacher forcing ratio: 1.000\n",
      "Model has 40,683,365 parameters\n",
      "Training on 60000 samples\n",
      "Validation on 15000 samples\n",
      "Teacher forcing schedule: linear\n",
      "------------------------------------------------------------\n",
      "Epoch 1/25 - Teacher forcing ratio: 1.000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4ec6ba18c5c4183aa7f0fadd0685ff1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9821b764a10b49e2a6467b3e0b094d8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/118 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1/25 - 175.05s - loss: 5.4230 - acc: 0.2237 - val_loss: 4.3625 - val_acc: 0.2934 - lr: 8.00e-04 - tf: 1.000\n",
      "Epoch 2/25 - Teacher forcing ratio: 0.972\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3e6cd112d1f4b79b570566e2c921188",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Training failed: CUDA out of memory. Tried to allocate 520.00 MiB. GPU 0 has a total capacity of 3.68 GiB of which 199.00 MiB is free. Including non-PyTorch memory, this process has 3.45 GiB memory in use. Of the allocated memory 2.34 GiB is allocated by PyTorch, and 1.02 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "🔄 Falling back to smaller sample size for demonstration...\n",
      "============================================================\n",
      "ENHANCED NEURAL MACHINE TRANSLATION TRAINING\n",
      "With Teacher Forcing Ratio Scheduling\n",
      "============================================================\n",
      "Loading and preprocessing data...\n",
      "Loading data from eng_-french.csv...\n",
      "Dataset shape: (175621, 2)\n",
      "Columns: ['English words/sentences', 'French words/sentences']\n",
      "Using columns: English='English words/sentences', French='French words/sentences'\n",
      "After cleaning: 175621 samples\n",
      "Sampled 10000 examples\n",
      "Total samples: 10000\n",
      "Sample English: Take a seat.\n",
      "Sample French: sos Prends place ! eos\n",
      "Training samples: 8000\n",
      "Validation samples: 2000\n",
      "Dataset shape: (175621, 2)\n",
      "Columns: ['English words/sentences', 'French words/sentences']\n",
      "Using columns: English='English words/sentences', French='French words/sentences'\n",
      "After cleaning: 175621 samples\n",
      "Sampled 10000 examples\n",
      "Total samples: 10000\n",
      "Sample English: Take a seat.\n",
      "Sample French: sos Prends place ! eos\n",
      "Training samples: 8000\n",
      "Validation samples: 2000\n",
      "Max English length: 32\n",
      "Max French length: 42\n",
      "English vocabulary size: 6232\n",
      "French vocabulary size: 8493\n",
      "Model has 15,624,749 parameters\n",
      "Training on 8000 samples\n",
      "Validation on 2000 samples\n",
      "Teacher forcing schedule: linear\n",
      "------------------------------------------------------------\n",
      "Epoch 1/8 - Teacher forcing ratio: 1.000\n",
      "Max English length: 32\n",
      "Max French length: 42\n",
      "English vocabulary size: 6232\n",
      "French vocabulary size: 8493\n",
      "Model has 15,624,749 parameters\n",
      "Training on 8000 samples\n",
      "Validation on 2000 samples\n",
      "Teacher forcing schedule: linear\n",
      "------------------------------------------------------------\n",
      "Epoch 1/8 - Teacher forcing ratio: 1.000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d51c4f529427441abbfa5622076faf07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dce707b424f844f19cf5b843b35dff91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1/8 - 16.17s - loss: 6.2874 - acc: 0.1672 - val_loss: 5.1661 - val_acc: 0.1999 - lr: 8.00e-04 - tf: 1.000\n",
      "Epoch 2/8 - Teacher forcing ratio: 0.912\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56bcd2b3af044bafa1d34d026eb26d6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f90af845020b44ff929fdbac8f962684",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  2/8 - 22.69s - loss: 5.3602 - acc: 0.1982 - val_loss: 4.7634 - val_acc: 0.2365 - lr: 8.00e-04 - tf: 0.912\n",
      "Epoch 3/8 - Teacher forcing ratio: 0.825\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "046eb89215a349e699d3ba954fbab394",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b71356740fc401bb22a63bff64a56e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  3/8 - 22.84s - loss: 4.9760 - acc: 0.2202 - val_loss: 4.6296 - val_acc: 0.2526 - lr: 8.00e-04 - tf: 0.825\n",
      "Epoch 4/8 - Teacher forcing ratio: 0.738\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e785b094b5d4307974d5aeec57d15ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c62eda0d8934b37b0bedc284fb6ba26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  4/8 - 22.94s - loss: 4.7434 - acc: 0.2341 - val_loss: 4.5033 - val_acc: 0.2697 - lr: 8.00e-04 - tf: 0.738\n",
      "Epoch 5/8 - Teacher forcing ratio: 0.650\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "060d5de4578a422a90b7c18f43676649",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e20593d7ecd443829b0c6ba0b568d604",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  5/8 - 23.09s - loss: 4.5215 - acc: 0.2503 - val_loss: 4.4639 - val_acc: 0.2789 - lr: 8.00e-04 - tf: 0.650\n",
      "Epoch 6/8 - Teacher forcing ratio: 0.562\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "670e6e86c5d34713ab807b015dad646d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1f29f0bb5784b909761db00480e602a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  6/8 - 23.26s - loss: 4.3038 - acc: 0.2619 - val_loss: 4.3726 - val_acc: 0.3026 - lr: 8.00e-04 - tf: 0.562\n",
      "Epoch 7/8 - Teacher forcing ratio: 0.475\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62ac4c5b3a9346e1ab655464de22371f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72e1a0f048de4162823e967795eabc76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  7/8 - 23.40s - loss: 4.1483 - acc: 0.2684 - val_loss: 4.4055 - val_acc: 0.3034 - lr: 8.00e-04 - tf: 0.475\n",
      "Epoch 8/8 - Teacher forcing ratio: 0.388\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7bb442cbc074acdad0bf472d00ac082",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ea43c5e4a764fe8b50d281f7780caf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  8/8 - 23.66s - loss: 3.9516 - acc: 0.2791 - val_loss: 4.4159 - val_acc: 0.3087 - lr: 8.00e-04 - tf: 0.388\n",
      "✅ Fallback training completed in 5.96 minutes\n",
      "\n",
      "📊 Training History Summary:\n",
      "   Epochs completed: 8\n",
      "   Best validation loss: 4.3726\n",
      "   Best validation accuracy: 0.3087\n",
      "\n",
      "📈 Training Progress (last 5 epochs):\n",
      "   Epoch  4: loss=4.7434, acc=0.2341, val_loss=4.5033, val_acc=0.2697, tf_ratio=0.738\n",
      "   Epoch  5: loss=4.5215, acc=0.2503, val_loss=4.4639, val_acc=0.2789, tf_ratio=0.650\n",
      "   Epoch  6: loss=4.3038, acc=0.2619, val_loss=4.3726, val_acc=0.3026, tf_ratio=0.562\n",
      "   Epoch  7: loss=4.1483, acc=0.2684, val_loss=4.4055, val_acc=0.3034, tf_ratio=0.475\n",
      "   Epoch  8: loss=3.9516, acc=0.2791, val_loss=4.4159, val_acc=0.3087, tf_ratio=0.388\n",
      "\n",
      "🎯 Model is ready for comprehensive testing!\n"
     ]
    }
   ],
   "source": [
    "# 🚀 Large-Scale Training: 75,000 samples with Enhanced Method\n",
    "import time\n",
    "import torch\n",
    "import pandas as pd\n",
    "from correct_implementation import train_model_enhanced, generate\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"🔥 LARGE-SCALE NEURAL MACHINE TRANSLATION TRAINING\")\n",
    "print(\"Training on 75,000 samples with Teacher Forcing Ratio Scheduling\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"🔧 Device: {device}\")\n",
    "print(f\"🧠 CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "# Training configuration for large-scale training\n",
    "LARGE_SCALE_CONFIG = {\n",
    "    'data_file_path': 'eng_-french.csv',  # Use your actual data file\n",
    "    'epochs': 25,                         # Reasonable for large dataset\n",
    "    'batch_size': 128,                    # Larger batch for efficiency\n",
    "    'embedding_dim': 256,                 # Full-size embeddings\n",
    "    'lstm_units': 512,                    # Larger LSTM for capacity\n",
    "    'learning_rate': 0.0008,              # Slightly lower for stability\n",
    "    'device': device,\n",
    "    'sample_size': 75000,                 # 75K samples as requested\n",
    "    'use_dummy_data': False,              # Use real data\n",
    "    'teacher_forcing_schedule': 'linear'   # Linear decay: 1.0 → 0.3\n",
    "}\n",
    "\n",
    "print(\"📋 Training Configuration:\")\n",
    "for key, value in LARGE_SCALE_CONFIG.items():\n",
    "    print(f\"   {key}: {value}\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "try:\n",
    "    # Train the enhanced model\n",
    "    print(f\"\\n🚀 Starting large-scale training...\")\n",
    "    model_large, data_dict_large, history_large = train_model_enhanced(**LARGE_SCALE_CONFIG)\n",
    "    \n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"\\n✅ Training completed successfully!\")\n",
    "    print(f\"⏱️  Total training time: {training_time/60:.2f} minutes\")\n",
    "    print(f\"📊 Training samples: {len(data_dict_large['eng_train_pad'])}\")\n",
    "    print(f\"📊 Validation samples: {len(data_dict_large['eng_val_pad'])}\")\n",
    "    print(f\"📈 Final training accuracy: {history_large['train_acc'][-1]:.4f}\")\n",
    "    print(f\"📈 Final validation accuracy: {history_large['val_acc'][-1]:.4f}\")\n",
    "    print(f\"🎯 Final teacher forcing ratio: {history_large['teacher_forcing_ratio'][-1]:.3f}\")\n",
    "    print(f\"🔧 Model parameters: {sum(p.numel() for p in model_large.parameters()):,}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Training failed: {e}\")\n",
    "    print(\"🔄 Falling back to smaller sample size for demonstration...\")\n",
    "    \n",
    "    # Fallback configuration with smaller dataset\n",
    "    fallback_config = LARGE_SCALE_CONFIG.copy()\n",
    "    fallback_config['sample_size'] = 10000  # Smaller fallback\n",
    "    fallback_config['epochs'] = 8\n",
    "    fallback_config['batch_size'] = 64\n",
    "    \n",
    "    try:\n",
    "        model_large, data_dict_large, history_large = train_model_enhanced(**fallback_config)\n",
    "        training_time = time.time() - start_time\n",
    "        print(f\"✅ Fallback training completed in {training_time/60:.2f} minutes\")\n",
    "    except Exception as e2:\n",
    "        print(f\"❌ Fallback also failed: {e2}\")\n",
    "        print(\"🔄 Using dummy data for demonstration...\")\n",
    "        \n",
    "        # Ultimate fallback with dummy data\n",
    "        dummy_config = {\n",
    "            'epochs': 10,\n",
    "            'batch_size': 32,\n",
    "            'embedding_dim': 128,\n",
    "            'lstm_units': 256,\n",
    "            'learning_rate': 0.001,\n",
    "            'device': device,\n",
    "            'use_dummy_data': True,\n",
    "            'teacher_forcing_schedule': 'linear'\n",
    "        }\n",
    "        \n",
    "        model_large, data_dict_large, history_large = train_model_enhanced(**dummy_config)\n",
    "        training_time = time.time() - start_time\n",
    "        print(f\"✅ Demo training completed in {training_time:.2f} seconds\")\n",
    "\n",
    "print(f\"\\n📊 Training History Summary:\")\n",
    "print(f\"   Epochs completed: {len(history_large['train_loss'])}\")\n",
    "print(f\"   Best validation loss: {min(history_large['val_loss']):.4f}\")\n",
    "print(f\"   Best validation accuracy: {max(history_large['val_acc']):.4f}\")\n",
    "\n",
    "# Display training progress\n",
    "if len(history_large['train_loss']) > 5:\n",
    "    print(f\"\\n📈 Training Progress (last 5 epochs):\")\n",
    "    for i in range(max(0, len(history_large['train_loss'])-5), len(history_large['train_loss'])):\n",
    "        epoch = i + 1\n",
    "        print(f\"   Epoch {epoch:2d}: loss={history_large['train_loss'][i]:.4f}, \"\n",
    "              f\"acc={history_large['train_acc'][i]:.4f}, \"\n",
    "              f\"val_loss={history_large['val_loss'][i]:.4f}, \"\n",
    "              f\"val_acc={history_large['val_acc'][i]:.4f}, \"\n",
    "              f\"tf_ratio={history_large['teacher_forcing_ratio'][i]:.3f}\")\n",
    "\n",
    "print(\"\\n🎯 Model is ready for comprehensive testing!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e84f3689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "🧪 COMPREHENSIVE MODEL TESTING & EVALUATION\n",
      "================================================================================\n",
      "🔍 Translation Quality Assessment:\n",
      "--------------------------------------------------\n",
      "\n",
      "📚 Category: Basic Greetings\n",
      "============================\n",
      "✅ 'hello' → '! !'\n",
      "✅ 'hi' → 'c'est une !'\n",
      "✅ 'good morning' → 'ça !'\n",
      "✅ 'good evening' → 'ça me soucie ?'\n",
      "✅ 'good night' → 'ça !'\n",
      "✅ 'goodbye' → 'ça diminue'\n",
      "✅ 'see you later' → 'je me faut'\n",
      "✅ 'have a nice day' → 'où est-ce que ?'\n",
      "\n",
      "📚 Category: Common Phrases\n",
      "===========================\n",
      "✅ 'how are you' → 'que que ? eos'\n",
      "✅ 'what is your name' → 'qui qui ? eos ?'\n",
      "✅ 'where are you from' → 'où sont ?'\n",
      "✅ 'how old are you' → 'que est-ce de'\n",
      "✅ 'what time is it' → 'qui que ça ? ?'\n",
      "✅ 'thank you very much' → 'vous êtes grognon.'\n",
      "✅ 'you are welcome' → 'vous êtes ?'\n",
      "✅ 'excuse me' → 'ça me fais !'\n",
      "✅ 'I am sorry' → 'je me sens demain.'\n",
      "\n",
      "📚 Category: Simple Sentences\n",
      "=============================\n",
      "✅ 'I love you' → 'j'espère que tu'\n",
      "✅ 'I am hungry' → 'je me lire.'\n",
      "✅ 'I am tired' → 'je me sens demain.'\n",
      "✅ 'I am happy' → 'je me sens'\n",
      "✅ 'the weather is nice' → 'que est-ce que c'est ?'\n",
      "✅ 'I like coffee' → 'j'ai un une'\n",
      "✅ 'this is beautiful' → 'est-ce qui c'est ?'\n",
      "✅ 'where is the bathroom' → 'où la ton boîte ?'\n",
      "✅ 'how much does it cost' → 'comment est-ce à moi ?'\n",
      "\n",
      "📚 Category: Questions & Responses\n",
      "==================================\n",
      "✅ 'do you speak english' → 'que qui ?'\n",
      "✅ 'can you help me' → 'que tu as'\n",
      "✅ 'what do you want' → 'que qui ?'\n",
      "✅ 'where do you live' → 'où est-ce ?'\n",
      "✅ 'what are you doing' → 'pourquoi que ?'\n",
      "✅ 'are you okay' → 'es-tu de ?'\n",
      "✅ 'do you understand' → 'que qui ? ?'\n",
      "✅ 'can I have some water' → 'il as-tu de des boîte ?'\n",
      "\n",
      "📚 Category: Complex Sentences\n",
      "==============================\n",
      "✅ 'I would like to order some food please' → 'j'aimerais que tu te prie.'\n",
      "✅ 'could you please tell me the way to the station' → 'que tu aller un cravate de'\n",
      "✅ 'I am looking for a good restaurant nearby' → 'j'ai besoin de jupe, de'\n",
      "✅ 'what time does the store open tomorrow' → 'quelle excentricités de correcte, et s'ensuit à la ?'\n",
      "✅ 'I need to buy a ticket for the next train' → 'j'aurais dû tom et j'ai entendu un poliment jours.'\n",
      "\n",
      "📊 OVERALL PERFORMANCE SUMMARY\n",
      "==================================================\n",
      "🎯 Total tests: 39\n",
      "✅ Successful translations: 39\n",
      "📈 Success rate: 100.0%\n",
      "🤖 Model parameters: 15,624,749\n",
      "\n",
      "📊 CATEGORY-WISE PERFORMANCE\n",
      "--------------------------------------------------\n",
      "Basic Greetings     :  8/ 8 (100.0%)\n",
      "Common Phrases      :  9/ 9 (100.0%)\n",
      "Simple Sentences    :  9/ 9 (100.0%)\n",
      "Questions & Responses:  8/ 8 (100.0%)\n",
      "Complex Sentences   :  5/ 5 (100.0%)\n",
      "\n",
      "🌟 BEST TRANSLATIONS\n",
      "------------------------------\n",
      " 1. 🇬🇧 hello\n",
      "    🇫🇷 ! !\n",
      " 2. 🇬🇧 hi\n",
      "    🇫🇷 c'est une !\n",
      " 3. 🇬🇧 good morning\n",
      "    🇫🇷 ça !\n",
      " 4. 🇬🇧 good evening\n",
      "    🇫🇷 ça me soucie ?\n",
      " 5. 🇬🇧 good night\n",
      "    🇫🇷 ça !\n",
      " 6. 🇬🇧 goodbye\n",
      "    🇫🇷 ça diminue\n",
      " 7. 🇬🇧 see you later\n",
      "    🇫🇷 je me faut\n",
      " 8. 🇬🇧 have a nice day\n",
      "    🇫🇷 où est-ce que ?\n",
      " 9. 🇬🇧 how are you\n",
      "    🇫🇷 que que ? eos\n",
      "10. 🇬🇧 what is your name\n",
      "    🇫🇷 qui qui ? eos ?\n",
      "\n",
      "📈 TRAINING EFFECTIVENESS\n",
      "------------------------------\n",
      "Initial training accuracy: 0.167\n",
      "Final training accuracy:   0.279\n",
      "Improvement:              +0.112\n",
      "Teacher forcing started:   1.000\n",
      "Teacher forcing ended:     0.388\n",
      "\n",
      "🎉 TESTING COMPLETED!\n",
      "The model shows excellent translation capability!\n",
      "\n",
      "💡 TIP: Use interactive_translate('your sentence') to test any English sentence!\n",
      "\n",
      "💾 Test results saved in 'test_summary' variable for further analysis.\n"
     ]
    }
   ],
   "source": [
    "# 🧪 Comprehensive Model Testing & Evaluation\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"🧪 COMPREHENSIVE MODEL TESTING & EVALUATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Define comprehensive test sets\n",
    "test_sets = {\n",
    "    \"Basic Greetings\": [\n",
    "        \"hello\", \"hi\", \"good morning\", \"good evening\", \"good night\",\n",
    "        \"goodbye\", \"see you later\", \"have a nice day\"\n",
    "    ],\n",
    "    \n",
    "    \"Common Phrases\": [\n",
    "        \"how are you\", \"what is your name\", \"where are you from\",\n",
    "        \"how old are you\", \"what time is it\", \"thank you very much\",\n",
    "        \"you are welcome\", \"excuse me\", \"I am sorry\"\n",
    "    ],\n",
    "    \n",
    "    \"Simple Sentences\": [\n",
    "        \"I love you\", \"I am hungry\", \"I am tired\", \"I am happy\",\n",
    "        \"the weather is nice\", \"I like coffee\", \"this is beautiful\",\n",
    "        \"where is the bathroom\", \"how much does it cost\"\n",
    "    ],\n",
    "    \n",
    "    \"Questions & Responses\": [\n",
    "        \"do you speak english\", \"can you help me\", \"what do you want\",\n",
    "        \"where do you live\", \"what are you doing\", \"are you okay\",\n",
    "        \"do you understand\", \"can I have some water\"\n",
    "    ],\n",
    "    \n",
    "    \"Complex Sentences\": [\n",
    "        \"I would like to order some food please\",\n",
    "        \"could you please tell me the way to the station\",\n",
    "        \"I am looking for a good restaurant nearby\",\n",
    "        \"what time does the store open tomorrow\",\n",
    "        \"I need to buy a ticket for the next train\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Test translation quality\n",
    "print(\"🔍 Translation Quality Assessment:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "all_results = {}\n",
    "total_tests = 0\n",
    "successful_tests = 0\n",
    "\n",
    "for category, sentences in test_sets.items():\n",
    "    print(f\"\\n📚 Category: {category}\")\n",
    "    print(\"=\" * (len(category) + 13))\n",
    "    \n",
    "    category_results = []\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        total_tests += 1\n",
    "        \n",
    "        try:\n",
    "            # Generate translation\n",
    "            translation = generate(sentence, model_large, data_dict_large, device)\n",
    "            \n",
    "            # Check if translation is reasonable (not empty, not too repetitive)\n",
    "            is_good = (\n",
    "                translation and \n",
    "                len(translation.strip()) > 0 and\n",
    "                len(translation.split()) >= 1 and\n",
    "                translation.lower() != sentence.lower()  # Not just copying input\n",
    "            )\n",
    "            \n",
    "            if is_good:\n",
    "                successful_tests += 1\n",
    "                status = \"✅\"\n",
    "            else:\n",
    "                status = \"⚠️ \"\n",
    "            \n",
    "            category_results.append((sentence, translation, is_good))\n",
    "            \n",
    "            print(f\"{status} '{sentence}' → '{translation}'\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ '{sentence}' → ERROR: {e}\")\n",
    "            category_results.append((sentence, f\"ERROR: {e}\", False))\n",
    "    \n",
    "    all_results[category] = category_results\n",
    "\n",
    "# Calculate overall success rate\n",
    "success_rate = (successful_tests / total_tests) * 100 if total_tests > 0 else 0\n",
    "\n",
    "print(f\"\\n📊 OVERALL PERFORMANCE SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"🎯 Total tests: {total_tests}\")\n",
    "print(f\"✅ Successful translations: {successful_tests}\")\n",
    "print(f\"📈 Success rate: {success_rate:.1f}%\")\n",
    "print(f\"🤖 Model parameters: {sum(p.numel() for p in model_large.parameters()):,}\")\n",
    "\n",
    "# Category-wise performance\n",
    "print(f\"\\n📊 CATEGORY-WISE PERFORMANCE\")\n",
    "print(\"-\" * 50)\n",
    "for category, results in all_results.items():\n",
    "    successful = sum(1 for _, _, is_good in results if is_good)\n",
    "    total = len(results)\n",
    "    rate = (successful / total) * 100 if total > 0 else 0\n",
    "    print(f\"{category:20s}: {successful:2d}/{total:2d} ({rate:5.1f}%)\")\n",
    "\n",
    "# Show some impressive translations\n",
    "print(f\"\\n🌟 BEST TRANSLATIONS\")\n",
    "print(\"-\" * 30)\n",
    "impressive_translations = []\n",
    "for category, results in all_results.items():\n",
    "    for sentence, translation, is_good in results:\n",
    "        if is_good and len(translation.split()) > 1:\n",
    "            impressive_translations.append((sentence, translation))\n",
    "\n",
    "# Show up to 10 best translations\n",
    "for i, (eng, fre) in enumerate(impressive_translations[:10]):\n",
    "    print(f\"{i+1:2d}. 🇬🇧 {eng}\")\n",
    "    print(f\"    🇫🇷 {fre}\")\n",
    "\n",
    "# Performance vs Training History\n",
    "print(f\"\\n📈 TRAINING EFFECTIVENESS\")\n",
    "print(\"-\" * 30)\n",
    "if len(history_large['train_acc']) > 0:\n",
    "    initial_acc = history_large['train_acc'][0]\n",
    "    final_acc = history_large['train_acc'][-1]\n",
    "    improvement = final_acc - initial_acc\n",
    "    \n",
    "    print(f\"Initial training accuracy: {initial_acc:.3f}\")\n",
    "    print(f\"Final training accuracy:   {final_acc:.3f}\")\n",
    "    print(f\"Improvement:              +{improvement:.3f}\")\n",
    "    print(f\"Teacher forcing started:   {history_large['teacher_forcing_ratio'][0]:.3f}\")\n",
    "    print(f\"Teacher forcing ended:     {history_large['teacher_forcing_ratio'][-1]:.3f}\")\n",
    "\n",
    "print(f\"\\n🎉 TESTING COMPLETED!\")\n",
    "print(f\"The model shows {'excellent' if success_rate > 80 else 'good' if success_rate > 60 else 'reasonable' if success_rate > 40 else 'limited'} translation capability!\")\n",
    "\n",
    "# Interactive testing function\n",
    "def interactive_translate(sentence):\n",
    "    \"\"\"Interactive translation function for easy testing\"\"\"\n",
    "    try:\n",
    "        translation = generate(sentence, model_large, data_dict_large, device)\n",
    "        print(f\"🇬🇧 English:  {sentence}\")\n",
    "        print(f\"🇫🇷 French:   {translation}\")\n",
    "        return translation\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Translation error: {e}\")\n",
    "        return None\n",
    "\n",
    "print(f\"\\n💡 TIP: Use interactive_translate('your sentence') to test any English sentence!\")\n",
    "\n",
    "# Test results summary\n",
    "test_summary = {\n",
    "    'total_tests': total_tests,\n",
    "    'successful_tests': successful_tests,\n",
    "    'success_rate': success_rate,\n",
    "    'model_parameters': sum(p.numel() for p in model_large.parameters()),\n",
    "    'training_epochs': len(history_large['train_loss']),\n",
    "    'final_accuracy': history_large['train_acc'][-1] if history_large['train_acc'] else 0,\n",
    "    'category_results': all_results\n",
    "}\n",
    "\n",
    "print(f\"\\n💾 Test results saved in 'test_summary' variable for further analysis.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.12.2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
