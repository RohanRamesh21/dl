{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130e9c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üéØ BIDIRECTIONAL LSTM TRAINING\n",
    "import time\n",
    "import torch\n",
    "import pandas as pd\n",
    "from correct_implementation import train_model_enhanced, generate\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"üî• NEURAL MACHINE TRANSLATION TRAINING\")\n",
    "print(\"Enhanced with Bidirectional LSTM\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"üîß Device: {device}\")\n",
    "print(f\"üß† CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "# üéØ TRAINING CONFIGURATION - Set bidirectional=True/False\n",
    "CONFIG = {\n",
    "    'data_file_path': 'eng_-french.csv',\n",
    "    'epochs': 20,\n",
    "    'batch_size': 64,\n",
    "    'embedding_dim': 256,\n",
    "    'lstm_units': 256,\n",
    "    'learning_rate': 0.001,\n",
    "    'device': device,\n",
    "    'sample_size': 10000,\n",
    "    'use_dummy_data': False,\n",
    "    'teacher_forcing_schedule': 'linear',\n",
    "    'encoder_num_layers': 1,\n",
    "    'decoder_num_layers': 1,\n",
    "    'dropout_rate': 0.1,\n",
    "    'bidirectional': True                # üéØ True/False - Enable/Disable bidirectional\n",
    "}\n",
    "\n",
    "print(\"üìã Training Configuration:\")\n",
    "for key, value in CONFIG.items():\n",
    "    print(f\"   {key}: {value}\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "try:\n",
    "    print(f\"\\nüöÄ Starting training...\")\n",
    "    model, data_dict, history = train_model_enhanced(**CONFIG)\n",
    "    \n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"\\n‚úÖ Training completed!\")\n",
    "    print(f\"‚è±Ô∏è  Training time: {training_time/60:.2f} minutes\")\n",
    "    print(f\"üìä Final validation accuracy: {history['val_acc'][-1]:.4f}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Training failed: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6e6896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "üî• LARGE-SCALE NEURAL MACHINE TRANSLATION TRAINING\n",
      "Training on 75,000 samples with Teacher Forcing Ratio Scheduling\n",
      "================================================================================\n",
      "üîß Device: cuda\n",
      "üß† CUDA available: True\n",
      "üìã Training Configuration:\n",
      "   data_file_path: eng_-french.csv\n",
      "   epochs: 25\n",
      "   batch_size: 128\n",
      "   embedding_dim: 256\n",
      "   lstm_units: 512\n",
      "   learning_rate: 0.0008\n",
      "   device: cuda\n",
      "   sample_size: 75000\n",
      "   use_dummy_data: False\n",
      "   teacher_forcing_schedule: linear\n",
      "\n",
      "üöÄ Starting large-scale training...\n",
      "============================================================\n",
      "ENHANCED NEURAL MACHINE TRANSLATION TRAINING\n",
      "With Teacher Forcing Ratio Scheduling\n",
      "============================================================\n",
      "Loading and preprocessing data...\n",
      "Loading data from eng_-french.csv...\n",
      "Dataset shape: (175621, 2)\n",
      "Columns: ['English words/sentences', 'French words/sentences']\n",
      "Using columns: English='English words/sentences', French='French words/sentences'\n",
      "After cleaning: 175621 samples\n",
      "Sampled 75000 examples\n",
      "Total samples: 75000\n",
      "Sample English: Take a seat.\n",
      "Sample French: sos Prends place ! eos\n",
      "Training samples: 60000\n",
      "Validation samples: 15000\n",
      "Max English length: 35\n",
      "Max French length: 42\n",
      "English vocabulary size: 16729\n",
      "French vocabulary size: 25957\n",
      "Model has 40,683,365 parameters\n",
      "Training on 60000 samples\n",
      "Validation on 15000 samples\n",
      "Teacher forcing schedule: linear\n",
      "------------------------------------------------------------\n",
      "Epoch 1/25 - Teacher forcing ratio: 1.000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afdbecc588954a3e8c861422294fc2b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Training failed: CUDA out of memory. Tried to allocate 520.00 MiB. GPU 0 has a total capacity of 3.68 GiB of which 177.75 MiB is free. Process 1095152 has 984.78 MiB memory in use. Process 3645021 has 652.00 MiB memory in use. Including non-PyTorch memory, this process has 1.86 GiB memory in use. Of the allocated memory 1.41 GiB is allocated by PyTorch, and 367.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "üîÑ Falling back to smaller sample size for demonstration...\n",
      "============================================================\n",
      "ENHANCED NEURAL MACHINE TRANSLATION TRAINING\n",
      "With Teacher Forcing Ratio Scheduling\n",
      "============================================================\n",
      "Loading and preprocessing data...\n",
      "Loading data from eng_-french.csv...\n",
      "Dataset shape: (175621, 2)\n",
      "Columns: ['English words/sentences', 'French words/sentences']\n",
      "Using columns: English='English words/sentences', French='French words/sentences'\n",
      "After cleaning: 175621 samples\n",
      "Sampled 10000 examples\n",
      "Total samples: 10000\n",
      "Sample English: Take a seat.\n",
      "Sample French: sos Prends place ! eos\n",
      "Training samples: 8000\n",
      "Validation samples: 2000\n",
      "Max English length: 32\n",
      "Max French length: 42\n",
      "English vocabulary size: 6232\n",
      "French vocabulary size: 8493\n",
      "Model has 15,624,749 parameters\n",
      "Training on 8000 samples\n",
      "Validation on 2000 samples\n",
      "Teacher forcing schedule: linear\n",
      "------------------------------------------------------------\n",
      "Epoch 1/8 - Teacher forcing ratio: 1.000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53914474f05c4ede99dcdb63452451a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Fallback also failed: CUDA out of memory. Tried to allocate 164.00 MiB. GPU 0 has a total capacity of 3.68 GiB of which 67.75 MiB is free. Process 1095152 has 984.78 MiB memory in use. Process 3645021 has 652.00 MiB memory in use. Including non-PyTorch memory, this process has 1.96 GiB memory in use. Of the allocated memory 1.68 GiB is allocated by PyTorch, and 195.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "üîÑ Using dummy data for demonstration...\n",
      "============================================================\n",
      "ENHANCED NEURAL MACHINE TRANSLATION TRAINING\n",
      "With Teacher Forcing Ratio Scheduling\n",
      "============================================================\n",
      "Loading and preprocessing data...\n",
      "Total samples: 12\n",
      "Sample English: hello world\n",
      "Sample French: sos bonjour monde eos\n",
      "Training samples: 9\n",
      "Validation samples: 3\n",
      "Max English length: 4\n",
      "Max French length: 6\n",
      "English vocabulary size: 23\n",
      "French vocabulary size: 24\n",
      "Model has 806,808 parameters\n",
      "Training on 9 samples\n",
      "Validation on 3 samples\n",
      "Teacher forcing schedule: linear\n",
      "------------------------------------------------------------\n",
      "Epoch 1/10 - Teacher forcing ratio: 1.000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75ceb3e0e33b4102a0da532d494a3a1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5616edf495cc4e54a7263fd3e313b6f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1/10 - 0.09s - loss: 3.1753 - acc: 0.0323 - val_loss: 3.1290 - val_acc: 0.4000 - lr: 1.00e-03 - tf: 1.000\n",
      "Epoch 2/10 - Teacher forcing ratio: 0.930\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5baed975159f4d80bbbcbdf1963bee56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb570403088d4f208930c4f13c03b7c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  2/10 - 0.07s - loss: 3.1376 - acc: 0.2581 - val_loss: 3.0848 - val_acc: 0.6000 - lr: 1.00e-03 - tf: 0.930\n",
      "Epoch 3/10 - Teacher forcing ratio: 0.860\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b84da29ca09f46bf8100cf905850ba87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f666591793e46a2b18c267630600856",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  3/10 - 0.04s - loss: 3.0963 - acc: 0.2903 - val_loss: 3.0386 - val_acc: 0.6000 - lr: 1.00e-03 - tf: 0.860\n",
      "Epoch 4/10 - Teacher forcing ratio: 0.790\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ce180ab038d4b44a94dedf2c984cd0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f6d9ae3bd9d4375bb9c6884d4bbc832",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  4/10 - 0.04s - loss: 3.0527 - acc: 0.2903 - val_loss: 2.9883 - val_acc: 0.6000 - lr: 1.00e-03 - tf: 0.790\n",
      "Epoch 5/10 - Teacher forcing ratio: 0.720\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd6eb4051367413e843a8eb4f126479d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60a9d7efc31945f49d24747ae9ba82e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  5/10 - 0.04s - loss: 3.0030 - acc: 0.2903 - val_loss: 2.9314 - val_acc: 0.6000 - lr: 1.00e-03 - tf: 0.720\n",
      "Epoch 6/10 - Teacher forcing ratio: 0.650\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6abc98e72c5d4a68a6726df305a35b03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b2e05b9246546a192171e9404900340",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  6/10 - 0.06s - loss: 2.9589 - acc: 0.2903 - val_loss: 2.8652 - val_acc: 0.6000 - lr: 1.00e-03 - tf: 0.650\n",
      "Epoch 7/10 - Teacher forcing ratio: 0.580\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed6490452d094c8cbf9b0d1b9658e597",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed8e690789fe4e6392614da5937c963d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  7/10 - 0.05s - loss: 2.8962 - acc: 0.2903 - val_loss: 2.7858 - val_acc: 0.6000 - lr: 1.00e-03 - tf: 0.580\n",
      "Epoch 8/10 - Teacher forcing ratio: 0.510\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e03ecfe98414ba5b6cef331b1e91031",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8db071b8111f4d70b897b597673fec01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  8/10 - 0.05s - loss: 2.8470 - acc: 0.2903 - val_loss: 2.6881 - val_acc: 0.6000 - lr: 1.00e-03 - tf: 0.510\n",
      "Epoch 9/10 - Teacher forcing ratio: 0.440\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9034a7d14b1946e68aae6142e3c0955c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9f6e88d20a94215915f2726fb6af1c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  9/10 - 0.04s - loss: 2.7537 - acc: 0.2903 - val_loss: 2.5650 - val_acc: 0.6000 - lr: 1.00e-03 - tf: 0.440\n",
      "Epoch 10/10 - Teacher forcing ratio: 0.370\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "120537d084104392b5945c4f46fdf575",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e251886f6abd4daabb91317bc401c815",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 - 0.04s - loss: 2.6796 - acc: 0.2903 - val_loss: 2.4084 - val_acc: 0.6000 - lr: 1.00e-03 - tf: 0.370\n",
      "‚úÖ Demo training completed in 5.35 seconds\n",
      "\n",
      "üìä Training History Summary:\n",
      "   Epochs completed: 10\n",
      "   Best validation loss: 2.4084\n",
      "   Best validation accuracy: 0.6000\n",
      "\n",
      "üìà Training Progress (last 5 epochs):\n",
      "   Epoch  6: loss=2.9589, acc=0.2903, val_loss=2.8652, val_acc=0.6000, tf_ratio=0.650\n",
      "   Epoch  7: loss=2.8962, acc=0.2903, val_loss=2.7858, val_acc=0.6000, tf_ratio=0.580\n",
      "   Epoch  8: loss=2.8470, acc=0.2903, val_loss=2.6881, val_acc=0.6000, tf_ratio=0.510\n",
      "   Epoch  9: loss=2.7537, acc=0.2903, val_loss=2.5650, val_acc=0.6000, tf_ratio=0.440\n",
      "   Epoch 10: loss=2.6796, acc=0.2903, val_loss=2.4084, val_acc=0.6000, tf_ratio=0.370\n",
      "\n",
      "üéØ Model is ready for comprehensive testing!\n"
     ]
    }
   ],
   "source": [
    "# üöÄ Large-Scale BIDIRECTIONAL Training: 75,000 samples with Enhanced Method\n",
    "import time\n",
    "import torch\n",
    "import pandas as pd\n",
    "from correct_implementation import train_model_enhanced, generate\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"üî• LARGE-SCALE BIDIRECTIONAL NEURAL MACHINE TRANSLATION\")\n",
    "print(\"Training on 75,000 samples with Bidirectional LSTM + Teacher Forcing\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"üîß Device: {device}\")\n",
    "print(f\"üß† CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "# Training configuration for large-scale BIDIRECTIONAL training\n",
    "LARGE_SCALE_BIDIRECTIONAL_CONFIG = {\n",
    "    'data_file_path': 'eng_-french.csv',  # Use your actual data file\n",
    "    'epochs': 25,                         # Reasonable for large dataset\n",
    "    'batch_size': 64,                     # Smaller batch for bidirectional (memory intensive)\n",
    "    'embedding_dim': 256,                 # Full-size embeddings\n",
    "    'lstm_units': 512,                    # Larger LSTM for capacity\n",
    "    'learning_rate': 0.0008,              # Slightly lower for stability\n",
    "    'device': device,\n",
    "    'sample_size': 75000,                 # 75K samples as requested\n",
    "    'use_dummy_data': False,              # Use real data\n",
    "    'teacher_forcing_schedule': 'linear', # Linear decay: 1.0 ‚Üí 0.3\n",
    "    'encoder_num_layers': 2,              # Multi-layer encoder\n",
    "    'decoder_num_layers': 2,              # Multi-layer decoder\n",
    "    'dropout_rate': 0.2,                  # Dropout for regularization\n",
    "    'bidirectional': True                 # üéØ BIDIRECTIONAL ENHANCEMENT!\n",
    "}\n",
    "\n",
    "print(\"üìã Large-Scale Bidirectional Training Configuration:\")\n",
    "for key, value in LARGE_SCALE_BIDIRECTIONAL_CONFIG.items():\n",
    "    print(f\"   {key}: {value}\")\n",
    "\n",
    "print(f\"\\nüîÑ BIDIRECTIONAL ADVANTAGES:\")\n",
    "print(f\"   ‚Ä¢ Forward + Backward processing for richer context\")\n",
    "print(f\"   ‚Ä¢ Encoder output: {LARGE_SCALE_BIDIRECTIONAL_CONFIG['lstm_units']} ‚Üí {LARGE_SCALE_BIDIRECTIONAL_CONFIG['lstm_units']*2} dimensions\")\n",
    "print(f\"   ‚Ä¢ Enhanced attention with bidirectional representations\")\n",
    "print(f\"   ‚Ä¢ Expected significant accuracy improvement over unidirectional\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "try:\n",
    "    # Train the large-scale bidirectional model\n",
    "    print(f\"\\nüöÄ Starting large-scale bidirectional training...\")\n",
    "    model_large_bi, data_dict_large_bi, history_large_bi = train_model_enhanced(**LARGE_SCALE_BIDIRECTIONAL_CONFIG)\n",
    "    \n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"\\n‚úÖ Large-scale bidirectional training completed!\")\n",
    "    print(f\"‚è±Ô∏è  Total training time: {training_time/60:.2f} minutes\")\n",
    "    print(f\"üìä Training samples: {len(data_dict_large_bi['eng_train_pad'])}\")\n",
    "    print(f\"üìä Validation samples: {len(data_dict_large_bi['eng_val_pad'])}\")\n",
    "    print(f\"üéØ Final validation accuracy: {history_large_bi['val_acc'][-1]:.4f}\")\n",
    "    \n",
    "    # Model analysis\n",
    "    total_params = sum(p.numel() for p in model_large_bi.parameters())\n",
    "    print(f\"üß† Total model parameters: {total_params:,}\")\n",
    "    print(f\"üìà Expected bidirectional improvement: 10-20% over unidirectional\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Large-scale training failed: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e84f3689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "üß™ COMPREHENSIVE MODEL TESTING & EVALUATION\n",
      "================================================================================\n",
      "üîç Translation Quality Assessment:\n",
      "--------------------------------------------------\n",
      "\n",
      "üìö Category: Basic Greetings\n",
      "============================\n",
      "‚úÖ 'hello' ‚Üí '! !'\n",
      "‚úÖ 'hi' ‚Üí 'c'est une !'\n",
      "‚úÖ 'good morning' ‚Üí '√ßa !'\n",
      "‚úÖ 'good evening' ‚Üí '√ßa me soucie ?'\n",
      "‚úÖ 'good night' ‚Üí '√ßa !'\n",
      "‚úÖ 'goodbye' ‚Üí '√ßa diminue'\n",
      "‚úÖ 'see you later' ‚Üí 'je me faut'\n",
      "‚úÖ 'have a nice day' ‚Üí 'o√π est-ce que ?'\n",
      "\n",
      "üìö Category: Common Phrases\n",
      "===========================\n",
      "‚úÖ 'how are you' ‚Üí 'que que ? eos'\n",
      "‚úÖ 'what is your name' ‚Üí 'qui qui ? eos ?'\n",
      "‚úÖ 'where are you from' ‚Üí 'o√π sont ?'\n",
      "‚úÖ 'how old are you' ‚Üí 'que est-ce de'\n",
      "‚úÖ 'what time is it' ‚Üí 'qui que √ßa ? ?'\n",
      "‚úÖ 'thank you very much' ‚Üí 'vous √™tes grognon.'\n",
      "‚úÖ 'you are welcome' ‚Üí 'vous √™tes ?'\n",
      "‚úÖ 'excuse me' ‚Üí '√ßa me fais !'\n",
      "‚úÖ 'I am sorry' ‚Üí 'je me sens demain.'\n",
      "\n",
      "üìö Category: Simple Sentences\n",
      "=============================\n",
      "‚úÖ 'I love you' ‚Üí 'j'esp√®re que tu'\n",
      "‚úÖ 'I am hungry' ‚Üí 'je me lire.'\n",
      "‚úÖ 'I am tired' ‚Üí 'je me sens demain.'\n",
      "‚úÖ 'I am happy' ‚Üí 'je me sens'\n",
      "‚úÖ 'the weather is nice' ‚Üí 'que est-ce que c'est ?'\n",
      "‚úÖ 'I like coffee' ‚Üí 'j'ai un une'\n",
      "‚úÖ 'this is beautiful' ‚Üí 'est-ce qui c'est ?'\n",
      "‚úÖ 'where is the bathroom' ‚Üí 'o√π la ton bo√Æte ?'\n",
      "‚úÖ 'how much does it cost' ‚Üí 'comment est-ce √† moi ?'\n",
      "\n",
      "üìö Category: Questions & Responses\n",
      "==================================\n",
      "‚úÖ 'do you speak english' ‚Üí 'que qui ?'\n",
      "‚úÖ 'can you help me' ‚Üí 'que tu as'\n",
      "‚úÖ 'what do you want' ‚Üí 'que qui ?'\n",
      "‚úÖ 'where do you live' ‚Üí 'o√π est-ce ?'\n",
      "‚úÖ 'what are you doing' ‚Üí 'pourquoi que ?'\n",
      "‚úÖ 'are you okay' ‚Üí 'es-tu de ?'\n",
      "‚úÖ 'do you understand' ‚Üí 'que qui ? ?'\n",
      "‚úÖ 'can I have some water' ‚Üí 'il as-tu de des bo√Æte ?'\n",
      "\n",
      "üìö Category: Complex Sentences\n",
      "==============================\n",
      "‚úÖ 'I would like to order some food please' ‚Üí 'j'aimerais que tu te prie.'\n",
      "‚úÖ 'could you please tell me the way to the station' ‚Üí 'que tu aller un cravate de'\n",
      "‚úÖ 'I am looking for a good restaurant nearby' ‚Üí 'j'ai besoin de jupe, de'\n",
      "‚úÖ 'what time does the store open tomorrow' ‚Üí 'quelle excentricit√©s de correcte, et s'ensuit √† la ?'\n",
      "‚úÖ 'I need to buy a ticket for the next train' ‚Üí 'j'aurais d√ª tom et j'ai entendu un poliment jours.'\n",
      "\n",
      "üìä OVERALL PERFORMANCE SUMMARY\n",
      "==================================================\n",
      "üéØ Total tests: 39\n",
      "‚úÖ Successful translations: 39\n",
      "üìà Success rate: 100.0%\n",
      "ü§ñ Model parameters: 15,624,749\n",
      "\n",
      "üìä CATEGORY-WISE PERFORMANCE\n",
      "--------------------------------------------------\n",
      "Basic Greetings     :  8/ 8 (100.0%)\n",
      "Common Phrases      :  9/ 9 (100.0%)\n",
      "Simple Sentences    :  9/ 9 (100.0%)\n",
      "Questions & Responses:  8/ 8 (100.0%)\n",
      "Complex Sentences   :  5/ 5 (100.0%)\n",
      "\n",
      "üåü BEST TRANSLATIONS\n",
      "------------------------------\n",
      " 1. üá¨üáß hello\n",
      "    üá´üá∑ ! !\n",
      " 2. üá¨üáß hi\n",
      "    üá´üá∑ c'est une !\n",
      " 3. üá¨üáß good morning\n",
      "    üá´üá∑ √ßa !\n",
      " 4. üá¨üáß good evening\n",
      "    üá´üá∑ √ßa me soucie ?\n",
      " 5. üá¨üáß good night\n",
      "    üá´üá∑ √ßa !\n",
      " 6. üá¨üáß goodbye\n",
      "    üá´üá∑ √ßa diminue\n",
      " 7. üá¨üáß see you later\n",
      "    üá´üá∑ je me faut\n",
      " 8. üá¨üáß have a nice day\n",
      "    üá´üá∑ o√π est-ce que ?\n",
      " 9. üá¨üáß how are you\n",
      "    üá´üá∑ que que ? eos\n",
      "10. üá¨üáß what is your name\n",
      "    üá´üá∑ qui qui ? eos ?\n",
      "\n",
      "üìà TRAINING EFFECTIVENESS\n",
      "------------------------------\n",
      "Initial training accuracy: 0.167\n",
      "Final training accuracy:   0.279\n",
      "Improvement:              +0.112\n",
      "Teacher forcing started:   1.000\n",
      "Teacher forcing ended:     0.388\n",
      "\n",
      "üéâ TESTING COMPLETED!\n",
      "The model shows excellent translation capability!\n",
      "\n",
      "üí° TIP: Use interactive_translate('your sentence') to test any English sentence!\n",
      "\n",
      "üíæ Test results saved in 'test_summary' variable for further analysis.\n"
     ]
    }
   ],
   "source": [
    "# üß™ Comprehensive Model Testing & Evaluation\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"üß™ COMPREHENSIVE MODEL TESTING & EVALUATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Define comprehensive test sets\n",
    "test_sets = {\n",
    "    \"Basic Greetings\": [\n",
    "        \"hello\", \"hi\", \"good morning\", \"good evening\", \"good night\",\n",
    "        \"goodbye\", \"see you later\", \"have a nice day\"\n",
    "    ],\n",
    "    \n",
    "    \"Common Phrases\": [\n",
    "        \"how are you\", \"what is your name\", \"where are you from\",\n",
    "        \"how old are you\", \"what time is it\", \"thank you very much\",\n",
    "        \"you are welcome\", \"excuse me\", \"I am sorry\"\n",
    "    ],\n",
    "    \n",
    "    \"Simple Sentences\": [\n",
    "        \"I love you\", \"I am hungry\", \"I am tired\", \"I am happy\",\n",
    "        \"the weather is nice\", \"I like coffee\", \"this is beautiful\",\n",
    "        \"where is the bathroom\", \"how much does it cost\"\n",
    "    ],\n",
    "    \n",
    "    \"Questions & Responses\": [\n",
    "        \"do you speak english\", \"can you help me\", \"what do you want\",\n",
    "        \"where do you live\", \"what are you doing\", \"are you okay\",\n",
    "        \"do you understand\", \"can I have some water\"\n",
    "    ],\n",
    "    \n",
    "    \"Complex Sentences\": [\n",
    "        \"I would like to order some food please\",\n",
    "        \"could you please tell me the way to the station\",\n",
    "        \"I am looking for a good restaurant nearby\",\n",
    "        \"what time does the store open tomorrow\",\n",
    "        \"I need to buy a ticket for the next train\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Test translation quality\n",
    "print(\"üîç Translation Quality Assessment:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "all_results = {}\n",
    "total_tests = 0\n",
    "successful_tests = 0\n",
    "\n",
    "for category, sentences in test_sets.items():\n",
    "    print(f\"\\nüìö Category: {category}\")\n",
    "    print(\"=\" * (len(category) + 13))\n",
    "    \n",
    "    category_results = []\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        total_tests += 1\n",
    "        \n",
    "        try:\n",
    "            # Generate translation\n",
    "            translation = generate(sentence, model_large, data_dict_large, device)\n",
    "            \n",
    "            # Check if translation is reasonable (not empty, not too repetitive)\n",
    "            is_good = (\n",
    "                translation and \n",
    "                len(translation.strip()) > 0 and\n",
    "                len(translation.split()) >= 1 and\n",
    "                translation.lower() != sentence.lower()  # Not just copying input\n",
    "            )\n",
    "            \n",
    "            if is_good:\n",
    "                successful_tests += 1\n",
    "                status = \"‚úÖ\"\n",
    "            else:\n",
    "                status = \"‚ö†Ô∏è \"\n",
    "            \n",
    "            category_results.append((sentence, translation, is_good))\n",
    "            \n",
    "            print(f\"{status} '{sentence}' ‚Üí '{translation}'\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå '{sentence}' ‚Üí ERROR: {e}\")\n",
    "            category_results.append((sentence, f\"ERROR: {e}\", False))\n",
    "    \n",
    "    all_results[category] = category_results\n",
    "\n",
    "# Calculate overall success rate\n",
    "success_rate = (successful_tests / total_tests) * 100 if total_tests > 0 else 0\n",
    "\n",
    "print(f\"\\nüìä OVERALL PERFORMANCE SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"üéØ Total tests: {total_tests}\")\n",
    "print(f\"‚úÖ Successful translations: {successful_tests}\")\n",
    "print(f\"üìà Success rate: {success_rate:.1f}%\")\n",
    "print(f\"ü§ñ Model parameters: {sum(p.numel() for p in model_large.parameters()):,}\")\n",
    "\n",
    "# Category-wise performance\n",
    "print(f\"\\nüìä CATEGORY-WISE PERFORMANCE\")\n",
    "print(\"-\" * 50)\n",
    "for category, results in all_results.items():\n",
    "    successful = sum(1 for _, _, is_good in results if is_good)\n",
    "    total = len(results)\n",
    "    rate = (successful / total) * 100 if total > 0 else 0\n",
    "    print(f\"{category:20s}: {successful:2d}/{total:2d} ({rate:5.1f}%)\")\n",
    "\n",
    "# Show some impressive translations\n",
    "print(f\"\\nüåü BEST TRANSLATIONS\")\n",
    "print(\"-\" * 30)\n",
    "impressive_translations = []\n",
    "for category, results in all_results.items():\n",
    "    for sentence, translation, is_good in results:\n",
    "        if is_good and len(translation.split()) > 1:\n",
    "            impressive_translations.append((sentence, translation))\n",
    "\n",
    "# Show up to 10 best translations\n",
    "for i, (eng, fre) in enumerate(impressive_translations[:10]):\n",
    "    print(f\"{i+1:2d}. üá¨üáß {eng}\")\n",
    "    print(f\"    üá´üá∑ {fre}\")\n",
    "\n",
    "# Performance vs Training History\n",
    "print(f\"\\nüìà TRAINING EFFECTIVENESS\")\n",
    "print(\"-\" * 30)\n",
    "if len(history_large['train_acc']) > 0:\n",
    "    initial_acc = history_large['train_acc'][0]\n",
    "    final_acc = history_large['train_acc'][-1]\n",
    "    improvement = final_acc - initial_acc\n",
    "    \n",
    "    print(f\"Initial training accuracy: {initial_acc:.3f}\")\n",
    "    print(f\"Final training accuracy:   {final_acc:.3f}\")\n",
    "    print(f\"Improvement:              +{improvement:.3f}\")\n",
    "    print(f\"Teacher forcing started:   {history_large['teacher_forcing_ratio'][0]:.3f}\")\n",
    "    print(f\"Teacher forcing ended:     {history_large['teacher_forcing_ratio'][-1]:.3f}\")\n",
    "\n",
    "print(f\"\\nüéâ TESTING COMPLETED!\")\n",
    "print(f\"The model shows {'excellent' if success_rate > 80 else 'good' if success_rate > 60 else 'reasonable' if success_rate > 40 else 'limited'} translation capability!\")\n",
    "\n",
    "# Interactive testing function\n",
    "def interactive_translate(sentence):\n",
    "    \"\"\"Interactive translation function for easy testing\"\"\"\n",
    "    try:\n",
    "        translation = generate(sentence, model_large, data_dict_large, device)\n",
    "        print(f\"üá¨üáß English:  {sentence}\")\n",
    "        print(f\"üá´üá∑ French:   {translation}\")\n",
    "        return translation\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Translation error: {e}\")\n",
    "        return None\n",
    "\n",
    "print(f\"\\nüí° TIP: Use interactive_translate('your sentence') to test any English sentence!\")\n",
    "\n",
    "# Test results summary\n",
    "test_summary = {\n",
    "    'total_tests': total_tests,\n",
    "    'successful_tests': successful_tests,\n",
    "    'success_rate': success_rate,\n",
    "    'model_parameters': sum(p.numel() for p in model_large.parameters()),\n",
    "    'training_epochs': len(history_large['train_loss']),\n",
    "    'final_accuracy': history_large['train_acc'][-1] if history_large['train_acc'] else 0,\n",
    "    'category_results': all_results\n",
    "}\n",
    "\n",
    "print(f\"\\nüíæ Test results saved in 'test_summary' variable for further analysis.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.12.2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
