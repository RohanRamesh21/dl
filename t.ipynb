{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "130e9c79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ðŸ”¥ NEURAL MACHINE TRANSLATION TRAINING\n",
      "Enhanced with Bidirectional LSTM\n",
      "================================================================================\n",
      "ðŸ”§ Device: cuda\n",
      "ðŸ§  CUDA available: True\n",
      "ðŸ“‹ Training Configuration:\n",
      "   data_file_path: eng_-french.csv\n",
      "   epochs: 20\n",
      "   batch_size: 64\n",
      "   embedding_dim: 256\n",
      "   lstm_units: 256\n",
      "   learning_rate: 0.001\n",
      "   device: cuda\n",
      "   sample_size: 1000\n",
      "   use_dummy_data: False\n",
      "   teacher_forcing_schedule: linear\n",
      "   encoder_num_layers: 1\n",
      "   decoder_num_layers: 1\n",
      "   dropout_rate: 0.1\n",
      "   bidirectional: True\n",
      "\n",
      "ðŸš€ Starting training...\n",
      "============================================================\n",
      "ENHANCED NEURAL MACHINE TRANSLATION TRAINING\n",
      "With Teacher Forcing Ratio Scheduling\n",
      "============================================================\n",
      "Loading and preprocessing data...\n",
      "Loading data from eng_-french.csv...\n",
      "Dataset shape: (175621, 2)\n",
      "Columns: ['English words/sentences', 'French words/sentences']\n",
      "Using columns: English='English words/sentences', French='French words/sentences'\n",
      "After cleaning: 175621 samples\n",
      "Sampled 1000 examples\n",
      "Total samples: 1000\n",
      "Sample English: Take a seat.\n",
      "Sample French: sos Prends place ! eos\n",
      "Training samples: 800\n",
      "Validation samples: 200\n",
      "Max English length: 16\n",
      "Max French length: 21\n",
      "English vocabulary size: 1504\n",
      "French vocabulary size: 1804\n",
      "Model has 4,467,469 parameters\n",
      "Training on 800 samples\n",
      "Validation on 200 samples\n",
      "Encoder: Bidirectional LSTM\n",
      "Teacher forcing schedule: linear\n",
      "------------------------------------------------------------\n",
      "Epoch 1/20 - Teacher forcing ratio: 1.000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6ee5d595a0243568c47061c38a2e953",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "962cab5e5a1d4ea8b167d2c57e9669f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1/20 - 1.19s - loss: 6.9400 - acc: 0.1293 - val_loss: 5.2825 - val_acc: 0.1812 - lr: 1.00e-03 - tf: 1.000\n",
      "Epoch 2/20 - Teacher forcing ratio: 0.965\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "001e5007664b411699cdc9ae5f9ac42a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5025ea28eaff4ef68de44ac0d1389112",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  2/20 - 1.10s - loss: 5.9691 - acc: 0.1400 - val_loss: 5.1110 - val_acc: 0.1812 - lr: 1.00e-03 - tf: 0.965\n",
      "Epoch 3/20 - Teacher forcing ratio: 0.930\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1906e025f83444ba8920c1aef45760c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7734228fbf734164941b7ea0257ee5d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  3/20 - 0.96s - loss: 5.8621 - acc: 0.1333 - val_loss: 4.9454 - val_acc: 0.1906 - lr: 1.00e-03 - tf: 0.930\n",
      "Epoch 4/20 - Teacher forcing ratio: 0.895\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18a1991884c944c5a1ba5937f1d97818",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8551b206cb6c4fecba224941e23f3bdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  4/20 - 0.96s - loss: 5.7391 - acc: 0.1384 - val_loss: 4.9152 - val_acc: 0.1906 - lr: 1.00e-03 - tf: 0.895\n",
      "Epoch 5/20 - Teacher forcing ratio: 0.860\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a82479d1d5a43f19d480348106d06dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71b221ff43c449f0984dc310e95eb23f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  5/20 - 0.98s - loss: 5.4645 - acc: 0.1565 - val_loss: 4.8629 - val_acc: 0.1925 - lr: 1.00e-03 - tf: 0.860\n",
      "Epoch 6/20 - Teacher forcing ratio: 0.825\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5184917911c425e8bc001882daf2cdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1419a707c54d45c38af975d8fd4cb0b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  6/20 - 0.85s - loss: 5.6300 - acc: 0.1270 - val_loss: 4.8388 - val_acc: 0.2016 - lr: 1.00e-03 - tf: 0.825\n",
      "Epoch 7/20 - Teacher forcing ratio: 0.790\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da98e3064d664a7fa34b4bf9a0654272",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a5eb9ef14bd410f9ae6527d83c36ed4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  7/20 - 0.90s - loss: 5.3552 - acc: 0.1484 - val_loss: 4.8365 - val_acc: 0.2138 - lr: 1.00e-03 - tf: 0.790\n",
      "Epoch 8/20 - Teacher forcing ratio: 0.755\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d7463157dbf4684b3d116cbb17a8d27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ba65e1d34d94e7f91cfd6be19c6b19f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  8/20 - 0.90s - loss: 5.1633 - acc: 0.1620 - val_loss: 4.7614 - val_acc: 0.2159 - lr: 1.00e-03 - tf: 0.755\n",
      "Epoch 9/20 - Teacher forcing ratio: 0.720\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e8fd267834746cd981cb0102efa8e81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8b8810ad92748b0888c4096da329dab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  9/20 - 1.00s - loss: 4.9782 - acc: 0.1774 - val_loss: 4.7527 - val_acc: 0.2152 - lr: 1.00e-03 - tf: 0.720\n",
      "Epoch 10/20 - Teacher forcing ratio: 0.685\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb17b14c2cae43c8a58d014b8746bc3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fdac0936fde4793ae9797f10f2238e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20 - 0.97s - loss: 4.8162 - acc: 0.1834 - val_loss: 4.7060 - val_acc: 0.2268 - lr: 1.00e-03 - tf: 0.685\n",
      "Epoch 11/20 - Teacher forcing ratio: 0.650\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98f3a9ed2d5c4b8786ade0699ff2e81f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fe6b5323e1b48c6b3bb85e4ff645317",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20 - 1.01s - loss: 4.6575 - acc: 0.1954 - val_loss: 4.6947 - val_acc: 0.2336 - lr: 1.00e-03 - tf: 0.650\n",
      "Epoch 12/20 - Teacher forcing ratio: 0.615\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a7655e2c79b438f9ef2dcf56149ddc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36d6b9b86af34b01967cb993bbc31df0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20 - 1.02s - loss: 4.5583 - acc: 0.2053 - val_loss: 4.7312 - val_acc: 0.2329 - lr: 1.00e-03 - tf: 0.615\n",
      "Epoch 13/20 - Teacher forcing ratio: 0.580\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "805f15c378ea4ec7ba0ec7ce35ca4762",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11905bfe16d542c5b8081e772dd9842a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20 - 1.05s - loss: 4.4170 - acc: 0.2105 - val_loss: 4.6446 - val_acc: 0.2480 - lr: 1.00e-03 - tf: 0.580\n",
      "Epoch 14/20 - Teacher forcing ratio: 0.545\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d04b7def5a64a259d8a92f4bebabdae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "954403137590414f949047f8b95fcd62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20 - 1.05s - loss: 4.3980 - acc: 0.2097 - val_loss: 4.7347 - val_acc: 0.2486 - lr: 1.00e-03 - tf: 0.545\n",
      "Epoch 15/20 - Teacher forcing ratio: 0.510\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08d0b76c36254686a2c2a5d20cbbcbd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75558bfb42d04a9d8b43206fbd555dda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20 - 1.01s - loss: 4.4725 - acc: 0.1963 - val_loss: 4.5963 - val_acc: 0.2528 - lr: 1.00e-03 - tf: 0.510\n",
      "Epoch 16/20 - Teacher forcing ratio: 0.475\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a575bbebde714dc2b8b257d48884b6b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a739bd624254e6e9e9aee2c34747f9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20 - 1.01s - loss: 4.3848 - acc: 0.2055 - val_loss: 4.6114 - val_acc: 0.2335 - lr: 1.00e-03 - tf: 0.475\n",
      "Epoch 17/20 - Teacher forcing ratio: 0.440\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06d705e20ebd414e8cf99bc84e373731",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53cb4755cbf143939f065292b7f83ba7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20 - 0.99s - loss: 4.3033 - acc: 0.2104 - val_loss: 4.6705 - val_acc: 0.2578 - lr: 1.00e-03 - tf: 0.440\n",
      "Epoch 18/20 - Teacher forcing ratio: 0.405\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faf95db1a3754bd9b8cab8d042c2e249",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70661a5c668e4bf7af7e2e9dfcab4d65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20 - 1.02s - loss: 4.1854 - acc: 0.2141 - val_loss: 4.6806 - val_acc: 0.2531 - lr: 1.00e-03 - tf: 0.405\n",
      "Epoch 19/20 - Teacher forcing ratio: 0.370\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ff7608189e64686b998b23937d97200",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "123aa8f814a146e1878a8b54a1ffb656",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20 - 0.97s - loss: 4.1687 - acc: 0.2123 - val_loss: 4.7400 - val_acc: 0.2531 - lr: 5.00e-04 - tf: 0.370\n",
      "Epoch 20/20 - Teacher forcing ratio: 0.335\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34745b6b3395440e92c7a4544a2b74b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e7c93b45be6401fb2833fb0d1b8b3f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20 - 0.98s - loss: 4.1047 - acc: 0.2126 - val_loss: 4.9393 - val_acc: 0.2398 - lr: 5.00e-04 - tf: 0.335\n",
      "\n",
      "âœ… Training completed!\n",
      "â±ï¸  Training time: 0.36 minutes\n",
      "ðŸ“Š Final validation accuracy: 0.2398\n"
     ]
    }
   ],
   "source": [
    "# ðŸŽ¯ BIDIRECTIONAL LSTM TRAINING\n",
    "import time\n",
    "import torch\n",
    "import pandas as pd\n",
    "from correct_implementation import train_model_enhanced, generate\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ðŸ”¥ NEURAL MACHINE TRANSLATION TRAINING\")\n",
    "print(\"Enhanced with Bidirectional LSTM\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"ðŸ”§ Device: {device}\")\n",
    "print(f\"ðŸ§  CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "# ðŸŽ¯ TRAINING CONFIGURATION - Set bidirectional=True/False\n",
    "CONFIG = {\n",
    "    'data_file_path': 'eng_-french.csv',\n",
    "    'epochs': 20,\n",
    "    'batch_size': 64,\n",
    "    'embedding_dim': 256,\n",
    "    'lstm_units': 256,\n",
    "    'learning_rate': 0.001,\n",
    "    'device': device,\n",
    "    'sample_size': 1000,\n",
    "    'use_dummy_data': False,\n",
    "    'teacher_forcing_schedule': 'linear',\n",
    "    'encoder_num_layers': 1,\n",
    "    'decoder_num_layers': 1,\n",
    "    'dropout_rate': 0.1,\n",
    "    'bidirectional': True                # ðŸŽ¯ True/False - Enable/Disable bidirectional\n",
    "}\n",
    "\n",
    "print(\"ðŸ“‹ Training Configuration:\")\n",
    "for key, value in CONFIG.items():\n",
    "    print(f\"   {key}: {value}\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "try:\n",
    "    print(f\"\\nðŸš€ Starting training...\")\n",
    "    model, data_dict, history = train_model_enhanced(**CONFIG)\n",
    "    \n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"\\nâœ… Training completed!\")\n",
    "    print(f\"â±ï¸  Training time: {training_time/60:.2f} minutes\")\n",
    "    print(f\"ðŸ“Š Final validation accuracy: {history['val_acc'][-1]:.4f}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Training failed: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c6e6896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ðŸ”¥ LARGE-SCALE BIDIRECTIONAL NEURAL MACHINE TRANSLATION\n",
      "Training on 75,000 samples with Bidirectional LSTM + Teacher Forcing\n",
      "================================================================================\n",
      "ðŸ”§ Device: cuda\n",
      "ðŸ§  CUDA available: True\n",
      "ðŸ“‹ Large-Scale Bidirectional Training Configuration:\n",
      "   data_file_path: eng_-french.csv\n",
      "   epochs: 15\n",
      "   batch_size: 64\n",
      "   embedding_dim: 256\n",
      "   lstm_units: 512\n",
      "   learning_rate: 0.0008\n",
      "   device: cuda\n",
      "   sample_size: 7500\n",
      "   use_dummy_data: False\n",
      "   teacher_forcing_schedule: linear\n",
      "   encoder_num_layers: 2\n",
      "   decoder_num_layers: 2\n",
      "   dropout_rate: 0.2\n",
      "   bidirectional: True\n",
      "\n",
      "ðŸ”„ BIDIRECTIONAL ADVANTAGES:\n",
      "   â€¢ Forward + Backward processing for richer context\n",
      "   â€¢ Encoder output: 512 â†’ 1024 dimensions\n",
      "   â€¢ Enhanced attention with bidirectional representations\n",
      "   â€¢ Expected significant accuracy improvement over unidirectional\n",
      "\n",
      "ðŸš€ Starting large-scale bidirectional training...\n",
      "============================================================\n",
      "ENHANCED NEURAL MACHINE TRANSLATION TRAINING\n",
      "With Teacher Forcing Ratio Scheduling\n",
      "============================================================\n",
      "Loading and preprocessing data...\n",
      "Loading data from eng_-french.csv...\n",
      "Dataset shape: (175621, 2)\n",
      "Columns: ['English words/sentences', 'French words/sentences']\n",
      "Using columns: English='English words/sentences', French='French words/sentences'\n",
      "After cleaning: 175621 samples\n",
      "Sampled 7500 examples\n",
      "Total samples: 7500\n",
      "Sample English: Take a seat.\n",
      "Sample French: sos Prends place ! eos\n",
      "Training samples: 6000\n",
      "Validation samples: 1500\n",
      "Max English length: 32\n",
      "Max French length: 42\n",
      "English vocabulary size: 5278\n",
      "French vocabulary size: 7103\n",
      "Model has 29,831,872 parameters\n",
      "Training on 6000 samples\n",
      "Validation on 1500 samples\n",
      "Encoder: Bidirectional LSTM\n",
      "Teacher forcing schedule: linear\n",
      "------------------------------------------------------------\n",
      "Epoch 1/15 - Teacher forcing ratio: 1.000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eed23e2346c64b8db3dac640dfca9d35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4659b4f3be67414e982a262b04048fef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1/15 - 32.84s - loss: 6.3399 - acc: 0.1641 - val_loss: 5.1942 - val_acc: 0.1983 - lr: 8.00e-04 - tf: 1.000\n",
      "Model saved to best_model.pt (Epoch 1, Val Acc: 0.1983, Val Loss: 5.1942)\n",
      "Epoch 2/15 - Teacher forcing ratio: 0.953\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02fe7a4250ab478e9757726408f71d08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c54b0ce208e4cb7be0b21053eaf7c40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  2/15 - 43.46s - loss: 5.4371 - acc: 0.1902 - val_loss: 4.8909 - val_acc: 0.2232 - lr: 8.00e-04 - tf: 0.953\n",
      "Model saved to best_model.pt (Epoch 2, Val Acc: 0.2232, Val Loss: 4.8909)\n",
      "Epoch 3/15 - Teacher forcing ratio: 0.907\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9eb88d64fb564bb9bed09649b86c7c8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff35be126b094c888c0f491bffac362c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  3/15 - 41.34s - loss: 5.1145 - acc: 0.2098 - val_loss: 4.7855 - val_acc: 0.2206 - lr: 8.00e-04 - tf: 0.907\n",
      "Epoch 4/15 - Teacher forcing ratio: 0.860\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be14c72d4a3a4cc7b01520065f930fe2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c465b2a9e91d49a08c406254c08daef8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  4/15 - 47.00s - loss: 4.9106 - acc: 0.2166 - val_loss: 4.6827 - val_acc: 0.2353 - lr: 8.00e-04 - tf: 0.860\n",
      "Model saved to best_model.pt (Epoch 4, Val Acc: 0.2353, Val Loss: 4.6827)\n",
      "Epoch 5/15 - Teacher forcing ratio: 0.813\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c799816b6be4165a23d427cf73b6773",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4df6fcab378f4650808af189d1569766",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  5/15 - 44.18s - loss: 4.8181 - acc: 0.2166 - val_loss: 4.6472 - val_acc: 0.2359 - lr: 8.00e-04 - tf: 0.813\n",
      "Model saved to best_model.pt (Epoch 5, Val Acc: 0.2359, Val Loss: 4.6472)\n",
      "Epoch 6/15 - Teacher forcing ratio: 0.767\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae232b0bb167454294ba7c33ac384b02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dba2d2ab3cbc48e9889d87efacf5f99f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  6/15 - 47.35s - loss: 4.6491 - acc: 0.2267 - val_loss: 4.5787 - val_acc: 0.2366 - lr: 8.00e-04 - tf: 0.767\n",
      "Model saved to best_model.pt (Epoch 6, Val Acc: 0.2366, Val Loss: 4.5787)\n",
      "Epoch 7/15 - Teacher forcing ratio: 0.720\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbc4a13ee1ec4587b62e1148903e724c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "192a1bcfd9c64296aa69ea39a44c4f8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  7/15 - 50.02s - loss: 4.5296 - acc: 0.2380 - val_loss: 4.5763 - val_acc: 0.2492 - lr: 8.00e-04 - tf: 0.720\n",
      "Model saved to best_model.pt (Epoch 7, Val Acc: 0.2492, Val Loss: 4.5763)\n",
      "Epoch 8/15 - Teacher forcing ratio: 0.673\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "412b318943d64561bb72f8dda113d8cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d38b2a431a464a538bc488c7162b030b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  8/15 - 48.05s - loss: 4.4589 - acc: 0.2393 - val_loss: 4.5172 - val_acc: 0.2590 - lr: 8.00e-04 - tf: 0.673\n",
      "Model saved to best_model.pt (Epoch 8, Val Acc: 0.2590, Val Loss: 4.5172)\n",
      "Epoch 9/15 - Teacher forcing ratio: 0.627\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98839a1af8524384aa6702af4854e3d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "163696edf7d640e6abb6fc5559fc4197",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  9/15 - 46.84s - loss: 4.4089 - acc: 0.2453 - val_loss: 4.5140 - val_acc: 0.2603 - lr: 8.00e-04 - tf: 0.627\n",
      "Model saved to best_model.pt (Epoch 9, Val Acc: 0.2603, Val Loss: 4.5140)\n",
      "Epoch 10/15 - Teacher forcing ratio: 0.580\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88cc790be66d4393a7c473b60bae812e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85bc4513cf22400da08f0643bcf4a400",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/15 - 44.75s - loss: 4.4415 - acc: 0.2436 - val_loss: 4.5168 - val_acc: 0.2609 - lr: 8.00e-04 - tf: 0.580\n",
      "Model saved to best_model.pt (Epoch 10, Val Acc: 0.2609, Val Loss: 4.5168)\n",
      "Epoch 11/15 - Teacher forcing ratio: 0.533\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33fc164416ed41bfa4aea2d316d1a5c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61d053204adc423c9a548e84811ca4f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/15 - 43.69s - loss: 4.4236 - acc: 0.2456 - val_loss: 4.4534 - val_acc: 0.2706 - lr: 8.00e-04 - tf: 0.533\n",
      "Model saved to best_model.pt (Epoch 11, Val Acc: 0.2706, Val Loss: 4.4534)\n",
      "Epoch 12/15 - Teacher forcing ratio: 0.487\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed463bbca6f649559d4138d0ca2c78d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5fc89dbd3a24262afb79af5aa29dc6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/15 - 39.25s - loss: 4.4633 - acc: 0.2417 - val_loss: 4.4475 - val_acc: 0.2728 - lr: 8.00e-04 - tf: 0.487\n",
      "Model saved to best_model.pt (Epoch 12, Val Acc: 0.2728, Val Loss: 4.4475)\n",
      "Epoch 13/15 - Teacher forcing ratio: 0.440\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf60e9548da1401fafe38f8821366213",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "194b1b884b614d728dc438891c38b3f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/15 - 40.71s - loss: 4.4262 - acc: 0.2413 - val_loss: 4.4552 - val_acc: 0.2800 - lr: 8.00e-04 - tf: 0.440\n",
      "Model saved to best_model.pt (Epoch 13, Val Acc: 0.2800, Val Loss: 4.4552)\n",
      "Epoch 14/15 - Teacher forcing ratio: 0.393\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bffaeaf560e40a6898448040dc26618",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd2b237990f44c0da1faf93eaafc1e6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/15 - 36.16s - loss: 4.4172 - acc: 0.2376 - val_loss: 4.4700 - val_acc: 0.2740 - lr: 8.00e-04 - tf: 0.393\n",
      "Epoch 15/15 - Teacher forcing ratio: 0.347\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47d3644ff1e440deb5107589790744e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc11da422833489ebbd66c5134618bb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/15 - 33.14s - loss: 4.4472 - acc: 0.2339 - val_loss: 4.4649 - val_acc: 0.2756 - lr: 8.00e-04 - tf: 0.347\n",
      "\n",
      "Training completed!\n",
      "Best validation accuracy achieved: 0.2800\n",
      "Best model saved to: best_model.pt\n",
      "\n",
      "âœ… Large-scale bidirectional training completed!\n",
      "â±ï¸  Total training time: 10.71 minutes\n",
      "ðŸ“Š Training samples: 6000\n",
      "ðŸ“Š Validation samples: 1500\n",
      "ðŸŽ¯ Final validation accuracy: 0.2756\n",
      "ðŸ§  Total model parameters: 29,831,872\n",
      "ðŸ“ˆ Expected bidirectional improvement: 10-20% over unidirectional\n"
     ]
    }
   ],
   "source": [
    "# ðŸš€ Large-Scale BIDIRECTIONAL Training: 75,000 samples with Enhanced Method\n",
    "import time\n",
    "import torch\n",
    "import pandas as pd\n",
    "from correct_implementation import train_model_enhanced, generate\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ðŸ”¥ LARGE-SCALE BIDIRECTIONAL NEURAL MACHINE TRANSLATION\")\n",
    "print(\"Training on 75,000 samples with Bidirectional LSTM + Teacher Forcing\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"ðŸ”§ Device: {device}\")\n",
    "print(f\"ðŸ§  CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "# Training configuration for large-scale BIDIRECTIONAL training\n",
    "LARGE_SCALE_BIDIRECTIONAL_CONFIG = {\n",
    "    'data_file_path': 'eng_-french.csv',  # Use your actual data file\n",
    "    'epochs': 15,                         # Reasonable for large dataset\n",
    "    'batch_size': 64,                     # Smaller batch for bidirectional (memory intensive)\n",
    "    'embedding_dim': 256,                 # Full-size embeddings\n",
    "    'lstm_units': 512,                    # Larger LSTM for capacity\n",
    "    'learning_rate': 0.0008,              # Slightly lower for stability\n",
    "    'device': device,\n",
    "    'sample_size': 7500,                 # 75K samples as requested\n",
    "    'use_dummy_data': False,              # Use real data\n",
    "    'teacher_forcing_schedule': 'linear', # Linear decay: 1.0 â†’ 0.3\n",
    "    'encoder_num_layers': 2,              # Multi-layer encoder\n",
    "    'decoder_num_layers': 2,              # Multi-layer decoder\n",
    "    'dropout_rate': 0.2,                  # Dropout for regularization\n",
    "    'bidirectional': True                 # ðŸŽ¯ BIDIRECTIONAL ENHANCEMENT!\n",
    "}\n",
    "\n",
    "print(\"ðŸ“‹ Large-Scale Bidirectional Training Configuration:\")\n",
    "for key, value in LARGE_SCALE_BIDIRECTIONAL_CONFIG.items():\n",
    "    print(f\"   {key}: {value}\")\n",
    "\n",
    "print(f\"\\nðŸ”„ BIDIRECTIONAL ADVANTAGES:\")\n",
    "print(f\"   â€¢ Forward + Backward processing for richer context\")\n",
    "print(f\"   â€¢ Encoder output: {LARGE_SCALE_BIDIRECTIONAL_CONFIG['lstm_units']} â†’ {LARGE_SCALE_BIDIRECTIONAL_CONFIG['lstm_units']*2} dimensions\")\n",
    "print(f\"   â€¢ Enhanced attention with bidirectional representations\")\n",
    "print(f\"   â€¢ Expected significant accuracy improvement over unidirectional\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "try:\n",
    "    # Train the large-scale bidirectional model\n",
    "    print(f\"\\nðŸš€ Starting large-scale bidirectional training...\")\n",
    "    model_large_bi, data_dict_large_bi, history_large_bi = train_model_enhanced(**LARGE_SCALE_BIDIRECTIONAL_CONFIG)\n",
    "    \n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"\\nâœ… Large-scale bidirectional training completed!\")\n",
    "    print(f\"â±ï¸  Total training time: {training_time/60:.2f} minutes\")\n",
    "    print(f\"ðŸ“Š Training samples: {len(data_dict_large_bi['eng_train_pad'])}\")\n",
    "    print(f\"ðŸ“Š Validation samples: {len(data_dict_large_bi['eng_val_pad'])}\")\n",
    "    print(f\"ðŸŽ¯ Final validation accuracy: {history_large_bi['val_acc'][-1]:.4f}\")\n",
    "    \n",
    "    # Model analysis\n",
    "    total_params = sum(p.numel() for p in model_large_bi.parameters())\n",
    "    print(f\"ðŸ§  Total model parameters: {total_params:,}\")\n",
    "    print(f\"ðŸ“ˆ Expected bidirectional improvement: 10-20% over unidirectional\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Large-scale training failed: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e84f3689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ðŸ§ª COMPREHENSIVE MODEL TESTING & EVALUATION\n",
      "================================================================================\n",
      "ðŸ” Translation Quality Assessment:\n",
      "--------------------------------------------------\n",
      "\n",
      "ðŸ“š Category: Basic Greetings\n",
      "============================\n",
      "âœ… 'hello' â†’ 'le est a est de la'\n",
      "âœ… 'hi' â†’ 'tout les lions est la'\n",
      "âœ… 'good morning' â†’ 'c'est est de'\n",
      "âœ… 'good evening' â†’ 'tout sont un'\n",
      "âœ… 'good night' â†’ 'tom est de'\n",
      "âœ… 'hello' â†’ 'le est a est de la'\n",
      "âœ… 'hi' â†’ 'tout les lions est la'\n",
      "âœ… 'good morning' â†’ 'c'est est de'\n",
      "âœ… 'good evening' â†’ 'tout sont un'\n",
      "âœ… 'good night' â†’ 'tom est de'\n",
      "âœ… 'goodbye' â†’ 'c'est est de'\n",
      "âœ… 'see you later' â†’ 'comment Ãªtes-vous ? eos ?'\n",
      "âœ… 'have a nice day' â†’ 'tom vous de ? ?'\n",
      "\n",
      "ðŸ“š Category: Common Phrases\n",
      "===========================\n",
      "âœ… 'how are you' â†’ 'tom est ?'\n",
      "âœ… 'goodbye' â†’ 'c'est est de'\n",
      "âœ… 'see you later' â†’ 'comment Ãªtes-vous ? eos ?'\n",
      "âœ… 'have a nice day' â†’ 'tom vous de ? ?'\n",
      "\n",
      "ðŸ“š Category: Common Phrases\n",
      "===========================\n",
      "âœ… 'how are you' â†’ 'tom est ?'\n",
      "âœ… 'what is your name' â†’ 'quelle une de'\n",
      "âœ… 'where are you from' â†’ 'tom est de ?'\n",
      "âœ… 'how old are you' â†’ 'c'est un de'\n",
      "âœ… 'what time is it' â†’ 'tom est monde'\n",
      "âœ… 'thank you very much' â†’ 'as-tu dÃ©jÃ  de ?'\n",
      "âœ… 'what is your name' â†’ 'quelle une de'\n",
      "âœ… 'where are you from' â†’ 'tom est de ?'\n",
      "âœ… 'how old are you' â†’ 'c'est un de'\n",
      "âœ… 'what time is it' â†’ 'tom est monde'\n",
      "âœ… 'thank you very much' â†’ 'as-tu dÃ©jÃ  de ?'\n",
      "âœ… 'you are welcome' â†’ 'vous Ãªtes une Ã '\n",
      "âœ… 'excuse me' â†’ 'c'est un de ? ?'\n",
      "âœ… 'I am sorry' â†’ 'j'ai besoin de'\n",
      "\n",
      "ðŸ“š Category: Simple Sentences\n",
      "=============================\n",
      "âœ… 'you are welcome' â†’ 'vous Ãªtes une Ã '\n",
      "âœ… 'excuse me' â†’ 'c'est un de ? ?'\n",
      "âœ… 'I am sorry' â†’ 'j'ai besoin de'\n",
      "\n",
      "ðŸ“š Category: Simple Sentences\n",
      "=============================\n",
      "âœ… 'I love you' â†’ 'j'aimerais que Ã '\n",
      "âœ… 'I am hungry' â†’ 'j'ai Ã©tÃ© en la entraÃ®neur.'\n",
      "âœ… 'I am tired' â†’ 'je suis que de que'\n",
      "âœ… 'I am happy' â†’ 'il me de Ã  la'\n",
      "âœ… 'the weather is nice' â†’ 'le pÃ¨re de ne ne pas eos'\n",
      "âœ… 'I love you' â†’ 'j'aimerais que Ã '\n",
      "âœ… 'I am hungry' â†’ 'j'ai Ã©tÃ© en la entraÃ®neur.'\n",
      "âœ… 'I am tired' â†’ 'je suis que de que'\n",
      "âœ… 'I am happy' â†’ 'il me de Ã  la'\n",
      "âœ… 'the weather is nice' â†’ 'le pÃ¨re de ne ne pas eos'\n",
      "âœ… 'I like coffee' â†’ 'j'ai entendu la'\n",
      "âœ… 'this is beautiful' â†’ 'tom est de ?'\n",
      "âœ… 'where is the bathroom' â†’ 'c'est de eos'\n",
      "âœ… 'how much does it cost' â†’ 'tom a tom ? de'\n",
      "\n",
      "ðŸ“š Category: Questions & Responses\n",
      "==================================\n",
      "âœ… 'I like coffee' â†’ 'j'ai entendu la'\n",
      "âœ… 'this is beautiful' â†’ 'tom est de ?'\n",
      "âœ… 'where is the bathroom' â†’ 'c'est de eos'\n",
      "âœ… 'how much does it cost' â†’ 'tom a tom ? de'\n",
      "\n",
      "ðŸ“š Category: Questions & Responses\n",
      "==================================\n",
      "âœ… 'do you speak english' â†’ 'est-ce que vous es en Ã  mary.'\n",
      "âœ… 'can you help me' â†’ 'pourquoi tu de Ã  la ?'\n",
      "âœ… 'what do you want' â†’ 'si ne me trouve de que ?'\n",
      "âœ… 'where do you live' â†’ 'tom a un de'\n",
      "âœ… 'do you speak english' â†’ 'est-ce que vous es en Ã  mary.'\n",
      "âœ… 'can you help me' â†’ 'pourquoi tu de Ã  la ?'\n",
      "âœ… 'what do you want' â†’ 'si ne me trouve de que ?'\n",
      "âœ… 'where do you live' â†’ 'tom a un de'\n",
      "âœ… 'what are you doing' â†’ 'puis-je que ce ? ?'\n",
      "âœ… 'are you okay' â†’ 'as-tu une'\n",
      "âœ… 'do you understand' â†’ 'tom que ? ? ?'\n",
      "âœ… 'can I have some water' â†’ 'pourquoi tu ? ?'\n",
      "\n",
      "ðŸ“š Category: Complex Sentences\n",
      "==============================\n",
      "âœ… 'I would like to order some food please' â†’ 'j'ai une de'\n",
      "âœ… 'what are you doing' â†’ 'puis-je que ce ? ?'\n",
      "âœ… 'are you okay' â†’ 'as-tu une'\n",
      "âœ… 'do you understand' â†’ 'tom que ? ? ?'\n",
      "âœ… 'can I have some water' â†’ 'pourquoi tu ? ?'\n",
      "\n",
      "ðŸ“š Category: Complex Sentences\n",
      "==============================\n",
      "âœ… 'I would like to order some food please' â†’ 'j'ai une de'\n",
      "âœ… 'could you please tell me the way to the station' â†’ 'tom me de'\n",
      "âœ… 'I am looking for a good restaurant nearby' â†’ 'j'espÃ¨re que vous Ãªtes'\n",
      "âœ… 'what time does the store open tomorrow' â†’ 'c'est est de ?'\n",
      "âœ… 'I need to buy a ticket for the next train' â†’ 'je suis de de de'\n",
      "\n",
      "ðŸ“Š OVERALL PERFORMANCE SUMMARY\n",
      "==================================================\n",
      "ðŸŽ¯ Total tests: 39\n",
      "âœ… Successful translations: 39\n",
      "ðŸ“ˆ Success rate: 100.0%\n",
      "ðŸ¤– Model parameters: 29,831,872\n",
      "\n",
      "ðŸ“Š CATEGORY-WISE PERFORMANCE\n",
      "--------------------------------------------------\n",
      "Basic Greetings     :  8/ 8 (100.0%)\n",
      "Common Phrases      :  9/ 9 (100.0%)\n",
      "Simple Sentences    :  9/ 9 (100.0%)\n",
      "Questions & Responses:  8/ 8 (100.0%)\n",
      "Complex Sentences   :  5/ 5 (100.0%)\n",
      "\n",
      "ðŸŒŸ BEST TRANSLATIONS\n",
      "------------------------------\n",
      " 1. ðŸ‡¬ðŸ‡§ hello\n",
      "    ðŸ‡«ðŸ‡· le est a est de la\n",
      " 2. ðŸ‡¬ðŸ‡§ hi\n",
      "    ðŸ‡«ðŸ‡· tout les lions est la\n",
      " 3. ðŸ‡¬ðŸ‡§ good morning\n",
      "    ðŸ‡«ðŸ‡· c'est est de\n",
      " 4. ðŸ‡¬ðŸ‡§ good evening\n",
      "    ðŸ‡«ðŸ‡· tout sont un\n",
      " 5. ðŸ‡¬ðŸ‡§ good night\n",
      "    ðŸ‡«ðŸ‡· tom est de\n",
      " 6. ðŸ‡¬ðŸ‡§ goodbye\n",
      "    ðŸ‡«ðŸ‡· c'est est de\n",
      " 7. ðŸ‡¬ðŸ‡§ see you later\n",
      "    ðŸ‡«ðŸ‡· comment Ãªtes-vous ? eos ?\n",
      " 8. ðŸ‡¬ðŸ‡§ have a nice day\n",
      "    ðŸ‡«ðŸ‡· tom vous de ? ?\n",
      " 9. ðŸ‡¬ðŸ‡§ how are you\n",
      "    ðŸ‡«ðŸ‡· tom est ?\n",
      "10. ðŸ‡¬ðŸ‡§ what is your name\n",
      "    ðŸ‡«ðŸ‡· quelle une de\n",
      "\n",
      "ðŸ“ˆ TRAINING EFFECTIVENESS\n",
      "------------------------------\n",
      "Initial training accuracy: 0.164\n",
      "Final training accuracy:   0.234\n",
      "Improvement:              +0.070\n",
      "Teacher forcing started:   1.000\n",
      "Teacher forcing ended:     0.347\n",
      "\n",
      "ðŸŽ‰ TESTING COMPLETED!\n",
      "The model shows excellent translation capability!\n",
      "\n",
      "ðŸ’¡ TIP: Use interactive_translate('your sentence') to test any English sentence!\n",
      "\n",
      "ðŸ’¾ Test results saved in 'test_summary' variable for further analysis.\n",
      "âœ… 'could you please tell me the way to the station' â†’ 'tom me de'\n",
      "âœ… 'I am looking for a good restaurant nearby' â†’ 'j'espÃ¨re que vous Ãªtes'\n",
      "âœ… 'what time does the store open tomorrow' â†’ 'c'est est de ?'\n",
      "âœ… 'I need to buy a ticket for the next train' â†’ 'je suis de de de'\n",
      "\n",
      "ðŸ“Š OVERALL PERFORMANCE SUMMARY\n",
      "==================================================\n",
      "ðŸŽ¯ Total tests: 39\n",
      "âœ… Successful translations: 39\n",
      "ðŸ“ˆ Success rate: 100.0%\n",
      "ðŸ¤– Model parameters: 29,831,872\n",
      "\n",
      "ðŸ“Š CATEGORY-WISE PERFORMANCE\n",
      "--------------------------------------------------\n",
      "Basic Greetings     :  8/ 8 (100.0%)\n",
      "Common Phrases      :  9/ 9 (100.0%)\n",
      "Simple Sentences    :  9/ 9 (100.0%)\n",
      "Questions & Responses:  8/ 8 (100.0%)\n",
      "Complex Sentences   :  5/ 5 (100.0%)\n",
      "\n",
      "ðŸŒŸ BEST TRANSLATIONS\n",
      "------------------------------\n",
      " 1. ðŸ‡¬ðŸ‡§ hello\n",
      "    ðŸ‡«ðŸ‡· le est a est de la\n",
      " 2. ðŸ‡¬ðŸ‡§ hi\n",
      "    ðŸ‡«ðŸ‡· tout les lions est la\n",
      " 3. ðŸ‡¬ðŸ‡§ good morning\n",
      "    ðŸ‡«ðŸ‡· c'est est de\n",
      " 4. ðŸ‡¬ðŸ‡§ good evening\n",
      "    ðŸ‡«ðŸ‡· tout sont un\n",
      " 5. ðŸ‡¬ðŸ‡§ good night\n",
      "    ðŸ‡«ðŸ‡· tom est de\n",
      " 6. ðŸ‡¬ðŸ‡§ goodbye\n",
      "    ðŸ‡«ðŸ‡· c'est est de\n",
      " 7. ðŸ‡¬ðŸ‡§ see you later\n",
      "    ðŸ‡«ðŸ‡· comment Ãªtes-vous ? eos ?\n",
      " 8. ðŸ‡¬ðŸ‡§ have a nice day\n",
      "    ðŸ‡«ðŸ‡· tom vous de ? ?\n",
      " 9. ðŸ‡¬ðŸ‡§ how are you\n",
      "    ðŸ‡«ðŸ‡· tom est ?\n",
      "10. ðŸ‡¬ðŸ‡§ what is your name\n",
      "    ðŸ‡«ðŸ‡· quelle une de\n",
      "\n",
      "ðŸ“ˆ TRAINING EFFECTIVENESS\n",
      "------------------------------\n",
      "Initial training accuracy: 0.164\n",
      "Final training accuracy:   0.234\n",
      "Improvement:              +0.070\n",
      "Teacher forcing started:   1.000\n",
      "Teacher forcing ended:     0.347\n",
      "\n",
      "ðŸŽ‰ TESTING COMPLETED!\n",
      "The model shows excellent translation capability!\n",
      "\n",
      "ðŸ’¡ TIP: Use interactive_translate('your sentence') to test any English sentence!\n",
      "\n",
      "ðŸ’¾ Test results saved in 'test_summary' variable for further analysis.\n"
     ]
    }
   ],
   "source": [
    "# ðŸ§ª Comprehensive Model Testing & Evaluation\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ðŸ§ª COMPREHENSIVE MODEL TESTING & EVALUATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Define comprehensive test sets\n",
    "test_sets = {\n",
    "    \"Basic Greetings\": [\n",
    "        \"hello\", \"hi\", \"good morning\", \"good evening\", \"good night\",\n",
    "        \"goodbye\", \"see you later\", \"have a nice day\"\n",
    "    ],\n",
    "    \n",
    "    \"Common Phrases\": [\n",
    "        \"how are you\", \"what is your name\", \"where are you from\",\n",
    "        \"how old are you\", \"what time is it\", \"thank you very much\",\n",
    "        \"you are welcome\", \"excuse me\", \"I am sorry\"\n",
    "    ],\n",
    "    \n",
    "    \"Simple Sentences\": [\n",
    "        \"I love you\", \"I am hungry\", \"I am tired\", \"I am happy\",\n",
    "        \"the weather is nice\", \"I like coffee\", \"this is beautiful\",\n",
    "        \"where is the bathroom\", \"how much does it cost\"\n",
    "    ],\n",
    "    \n",
    "    \"Questions & Responses\": [\n",
    "        \"do you speak english\", \"can you help me\", \"what do you want\",\n",
    "        \"where do you live\", \"what are you doing\", \"are you okay\",\n",
    "        \"do you understand\", \"can I have some water\"\n",
    "    ],\n",
    "    \n",
    "    \"Complex Sentences\": [\n",
    "        \"I would like to order some food please\",\n",
    "        \"could you please tell me the way to the station\",\n",
    "        \"I am looking for a good restaurant nearby\",\n",
    "        \"what time does the store open tomorrow\",\n",
    "        \"I need to buy a ticket for the next train\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Test translation quality\n",
    "print(\"ðŸ” Translation Quality Assessment:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "all_results = {}\n",
    "total_tests = 0\n",
    "successful_tests = 0\n",
    "\n",
    "for category, sentences in test_sets.items():\n",
    "    print(f\"\\nðŸ“š Category: {category}\")\n",
    "    print(\"=\" * (len(category) + 13))\n",
    "    \n",
    "    category_results = []\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        total_tests += 1\n",
    "        \n",
    "        try:\n",
    "            # Generate translation using the bidirectional model\n",
    "            translation = generate(sentence, model_large_bi, data_dict_large_bi, device)\n",
    "            \n",
    "            # Check if translation is reasonable (not empty, not too repetitive)\n",
    "            is_good = (\n",
    "                translation and \n",
    "                len(translation.strip()) > 0 and\n",
    "                len(translation.split()) >= 1 and\n",
    "                translation.lower() != sentence.lower()  # Not just copying input\n",
    "            )\n",
    "            \n",
    "            if is_good:\n",
    "                successful_tests += 1\n",
    "                status = \"âœ…\"\n",
    "            else:\n",
    "                status = \"âš ï¸ \"\n",
    "            \n",
    "            category_results.append((sentence, translation, is_good))\n",
    "            \n",
    "            print(f\"{status} '{sentence}' â†’ '{translation}'\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ '{sentence}' â†’ ERROR: {e}\")\n",
    "            category_results.append((sentence, f\"ERROR: {e}\", False))\n",
    "    \n",
    "    all_results[category] = category_results\n",
    "\n",
    "# Calculate overall success rate\n",
    "success_rate = (successful_tests / total_tests) * 100 if total_tests > 0 else 0\n",
    "\n",
    "print(f\"\\nðŸ“Š OVERALL PERFORMANCE SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"ðŸŽ¯ Total tests: {total_tests}\")\n",
    "print(f\"âœ… Successful translations: {successful_tests}\")\n",
    "print(f\"ðŸ“ˆ Success rate: {success_rate:.1f}%\")\n",
    "print(f\"ðŸ¤– Model parameters: {sum(p.numel() for p in model_large_bi.parameters()):,}\")\n",
    "\n",
    "# Category-wise performance\n",
    "print(f\"\\nðŸ“Š CATEGORY-WISE PERFORMANCE\")\n",
    "print(\"-\" * 50)\n",
    "for category, results in all_results.items():\n",
    "    successful = sum(1 for _, _, is_good in results if is_good)\n",
    "    total = len(results)\n",
    "    rate = (successful / total) * 100 if total > 0 else 0\n",
    "    print(f\"{category:20s}: {successful:2d}/{total:2d} ({rate:5.1f}%)\")\n",
    "\n",
    "# Show some impressive translations\n",
    "print(f\"\\nðŸŒŸ BEST TRANSLATIONS\")\n",
    "print(\"-\" * 30)\n",
    "impressive_translations = []\n",
    "for category, results in all_results.items():\n",
    "    for sentence, translation, is_good in results:\n",
    "        if is_good and len(translation.split()) > 1:\n",
    "            impressive_translations.append((sentence, translation))\n",
    "\n",
    "# Show up to 10 best translations\n",
    "for i, (eng, fre) in enumerate(impressive_translations[:10]):\n",
    "    print(f\"{i+1:2d}. ðŸ‡¬ðŸ‡§ {eng}\")\n",
    "    print(f\"    ðŸ‡«ðŸ‡· {fre}\")\n",
    "\n",
    "# Performance vs Training History\n",
    "print(f\"\\nðŸ“ˆ TRAINING EFFECTIVENESS\")\n",
    "print(\"-\" * 30)\n",
    "if len(history_large_bi['train_acc']) > 0:\n",
    "    initial_acc = history_large_bi['train_acc'][0]\n",
    "    final_acc = history_large_bi['train_acc'][-1]\n",
    "    improvement = final_acc - initial_acc\n",
    "    \n",
    "    print(f\"Initial training accuracy: {initial_acc:.3f}\")\n",
    "    print(f\"Final training accuracy:   {final_acc:.3f}\")\n",
    "    print(f\"Improvement:              +{improvement:.3f}\")\n",
    "    print(f\"Teacher forcing started:   {history_large_bi['teacher_forcing_ratio'][0]:.3f}\")\n",
    "    print(f\"Teacher forcing ended:     {history_large_bi['teacher_forcing_ratio'][-1]:.3f}\")\n",
    "\n",
    "print(f\"\\nðŸŽ‰ TESTING COMPLETED!\")\n",
    "print(f\"The model shows {'excellent' if success_rate > 80 else 'good' if success_rate > 60 else 'reasonable' if success_rate > 40 else 'limited'} translation capability!\")\n",
    "\n",
    "# Interactive testing function\n",
    "def interactive_translate(sentence):\n",
    "    \"\"\"Interactive translation function for easy testing\"\"\"\n",
    "    try:\n",
    "        translation = generate(sentence, model_large_bi, data_dict_large_bi, device)\n",
    "        print(f\"ðŸ‡¬ðŸ‡§ English:  {sentence}\")\n",
    "        print(f\"ðŸ‡«ðŸ‡· French:   {translation}\")\n",
    "        return translation\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Translation error: {e}\")\n",
    "        return None\n",
    "\n",
    "print(f\"\\nðŸ’¡ TIP: Use interactive_translate('your sentence') to test any English sentence!\")\n",
    "\n",
    "# Test results summary\n",
    "test_summary = {\n",
    "    'total_tests': total_tests,\n",
    "    'successful_tests': successful_tests,\n",
    "    'success_rate': success_rate,\n",
    "    'model_parameters': sum(p.numel() for p in model_large_bi.parameters()),\n",
    "    'training_epochs': len(history_large_bi['train_loss']),\n",
    "    'final_accuracy': history_large_bi['train_acc'][-1] if history_large_bi['train_acc'] else 0,\n",
    "    'category_results': all_results\n",
    "}\n",
    "\n",
    "print(f\"\\nðŸ’¾ Test results saved in 'test_summary' variable for further analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f35f890",
   "metadata": {},
   "source": [
    "# ðŸ’¾ Model Saving & Loading Demo\n",
    "\n",
    "This cell demonstrates the new **automatic model saving functionality** that was added to the training pipeline. The enhanced training function now:\n",
    "\n",
    "- ðŸŽ¯ **Automatically saves the best model** based on validation accuracy\n",
    "- ðŸ“Š **Tracks both accuracy and loss** for comprehensive monitoring  \n",
    "- ðŸ”„ **Preserves complete model state** including weights, configuration, and training history\n",
    "- âš¡ **Easy loading** for inference or continued training\n",
    "\n",
    "## Key Features:\n",
    "- **Best Model Selection**: Saves only when validation accuracy improves\n",
    "- **Complete State**: Model weights + configuration + data dictionaries + history\n",
    "- **Cross-Device Compatible**: Save on GPU, load on CPU or vice versa\n",
    "- **Training Continuity**: Can resume training from saved checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9aa685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ’¾ Demonstrate Model Saving and Loading\n",
    "from correct_implementation import load_model, save_model\n",
    "import os\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ðŸ’¾ MODEL SAVING & LOADING DEMONSTRATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Check if we have a trained model to work with\n",
    "try:\n",
    "    # Use the bidirectional model from Cell 2 if available\n",
    "    current_model = model_large_bi\n",
    "    current_data_dict = data_dict_large_bi\n",
    "    current_history = history_large_bi\n",
    "    model_name = \"Bidirectional LSTM Model\"\n",
    "    print(f\"âœ… Using trained {model_name}\")\n",
    "except NameError:\n",
    "    try:\n",
    "        # Fallback to basic model from Cell 1 if available\n",
    "        current_model = model\n",
    "        current_data_dict = data_dict\n",
    "        current_history = history\n",
    "        model_name = \"Basic LSTM Model\"\n",
    "        print(f\"âœ… Using trained {model_name}\")\n",
    "    except NameError:\n",
    "        print(\"âŒ No trained model found! Please run Cell 1 or Cell 2 first.\")\n",
    "        current_model = None\n",
    "\n",
    "if current_model is not None:\n",
    "    # Show current model info\n",
    "    total_params = sum(p.numel() for p in current_model.parameters())\n",
    "    print(f\"ðŸ¤– Model parameters: {total_params:,}\")\n",
    "    print(f\"ðŸŽ¯ Architecture: {'Bidirectional' if current_model.bidirectional else 'Unidirectional'} LSTM\")\n",
    "    print(f\"ðŸ“Š Final validation accuracy: {current_history['val_acc'][-1]:.4f}\")\n",
    "    \n",
    "    # Demonstrate manual saving\n",
    "    manual_save_path = 'demo_manual_save.pt'\n",
    "    print(f\"\\nðŸ’¾ Manually saving model to '{manual_save_path}'...\")\n",
    "    \n",
    "    save_model(\n",
    "        model=current_model,\n",
    "        data_dict=current_data_dict, \n",
    "        history=current_history,\n",
    "        filepath=manual_save_path,\n",
    "        epoch=len(current_history['train_loss']),\n",
    "        val_acc=current_history['val_acc'][-1],\n",
    "        val_loss=current_history['val_loss'][-1]\n",
    "    )\n",
    "    \n",
    "    # Demonstrate loading\n",
    "    print(f\"\\nðŸ”„ Loading model from '{manual_save_path}'...\")\n",
    "    loaded_model, loaded_data_dict, loaded_history = load_model(manual_save_path, device=device)\n",
    "    \n",
    "    # Verify loaded model works\n",
    "    print(f\"\\nðŸ§ª Testing loaded model...\")\n",
    "    test_sentences = [\"hello\", \"thank you\", \"good morning\"]\n",
    "    \n",
    "    print(\"Original vs Loaded Model Comparison:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    for sentence in test_sentences:\n",
    "        try:\n",
    "            original_translation = generate(sentence, current_model, current_data_dict, device)\n",
    "            loaded_translation = generate(sentence, loaded_model, loaded_data_dict, device)\n",
    "            \n",
    "            match = \"âœ…\" if original_translation == loaded_translation else \"âš ï¸\"\n",
    "            print(f\"{match} '{sentence}':\")\n",
    "            print(f\"   Original: '{original_translation}'\")\n",
    "            print(f\"   Loaded:   '{loaded_translation}'\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error testing '{sentence}': {e}\")\n",
    "    \n",
    "    # Show automatic saving info\n",
    "    print(f\"\\nðŸŽ¯ AUTOMATIC SAVING INFO\")\n",
    "    print(\"-\" * 40)\n",
    "    print(\"â€¢ During training, the model is automatically saved when validation accuracy improves\")\n",
    "    print(\"â€¢ The 'save_path' parameter in train_model_enhanced() controls where it's saved\")\n",
    "    print(\"â€¢ Default save path is 'best_model.pt' in the current directory\")\n",
    "    print(\"â€¢ You can change it like: train_model_enhanced(..., save_path='my_best_model.pt')\")\n",
    "    \n",
    "    # Show what gets saved\n",
    "    print(f\"\\nðŸ“¦ WHAT GETS SAVED\")\n",
    "    print(\"-\" * 20)\n",
    "    print(\"âœ“ Complete model weights and parameters\")\n",
    "    print(\"âœ“ Model architecture configuration\")\n",
    "    print(\"âœ“ Tokenizers and vocabulary mappings\")\n",
    "    print(\"âœ“ Complete training history (loss, accuracy curves)\")\n",
    "    print(\"âœ“ Epoch number and best validation metrics\")\n",
    "    print(\"âœ“ All data preprocessing information\")\n",
    "    \n",
    "    # File size info\n",
    "    if os.path.exists(manual_save_path):\n",
    "        file_size = os.path.getsize(manual_save_path) / (1024 * 1024)  # MB\n",
    "        print(f\"\\nðŸ“ Saved model file size: {file_size:.2f} MB\")\n",
    "        \n",
    "        # Cleanup\n",
    "        os.remove(manual_save_path)\n",
    "        print(f\"ðŸ§¹ Cleaned up demo file: {manual_save_path}\")\n",
    "    \n",
    "    print(f\"\\nâœ… Model saving demonstration completed!\")\n",
    "    print(f\"ðŸ’¡ Your trained models are automatically saved during training with the new enhanced functionality!\")\n",
    "\n",
    "else:\n",
    "    print(\"\\nðŸ’¡ To see the model saving demo, please:\")\n",
    "    print(\"   1. Run Cell 1 (basic training) OR Cell 2 (large-scale training)\")\n",
    "    print(\"   2. Then run this cell again\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac43dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸŽ¯ Training with Custom Model Saving Example\n",
    "from correct_implementation import train_model_enhanced, load_model, generate\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ðŸŽ¯ ENHANCED TRAINING WITH AUTOMATIC MODEL SAVING\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Example: Train a small model with custom save path\n",
    "print(\"This cell demonstrates how to train with automatic model saving.\")\n",
    "print(\"The model will be saved automatically when validation accuracy improves!\\n\")\n",
    "\n",
    "# Configuration for a quick demo training\n",
    "DEMO_CONFIG = {\n",
    "    'use_dummy_data': True,           # Use dummy data for quick demo\n",
    "    'epochs': 5,                      # Short training for demo\n",
    "    'batch_size': 16,                 # Small batch\n",
    "    'embedding_dim': 64,              # Smaller for speed\n",
    "    'lstm_units': 64,                 # Smaller for speed\n",
    "    'device': device,\n",
    "    'bidirectional': True,            # Enable bidirectional\n",
    "    'save_path': 'demo_best_model.pt' # ðŸŽ¯ Custom save path!\n",
    "}\n",
    "\n",
    "print(\"ðŸ“‹ Demo Training Configuration:\")\n",
    "for key, value in DEMO_CONFIG.items():\n",
    "    print(f\"   {key}: {value}\")\n",
    "\n",
    "print(f\"\\nâš ï¸  NOTE: This is a quick demo with dummy data.\")\n",
    "print(f\"ðŸŽ¯ Key feature: save_path='demo_best_model.pt' - model will auto-save here!\")\n",
    "\n",
    "# Uncomment the lines below to run the demo training:\n",
    "print(f\"\\nðŸ’¡ To run this demo, uncomment the training code below:\")\n",
    "print(f\"   (It's commented out to avoid accidental long training runs)\")\n",
    "\n",
    "\"\"\"\n",
    "# Uncomment to run the demo training:\n",
    "print(f\"\\nðŸš€ Starting demo training with automatic saving...\")\n",
    "\n",
    "demo_model, demo_data_dict, demo_history = train_model_enhanced(**DEMO_CONFIG)\n",
    "\n",
    "print(f\"\\nâœ… Demo training completed!\")\n",
    "print(f\"ðŸ’¾ Best model automatically saved to: {DEMO_CONFIG['save_path']}\")\n",
    "\n",
    "# Load and test the automatically saved model\n",
    "print(f\"\\nðŸ”„ Loading the automatically saved best model...\")\n",
    "loaded_demo_model, loaded_demo_data_dict, loaded_demo_history = load_model(DEMO_CONFIG['save_path'])\n",
    "\n",
    "# Test translation\n",
    "test_translation = generate(\"hello world\", loaded_demo_model, loaded_demo_data_dict)\n",
    "print(f\"ðŸ§ª Test translation: 'hello world' â†’ '{test_translation}'\")\n",
    "\"\"\"\n",
    "\n",
    "print(f\"\\nðŸ“š USAGE EXAMPLES:\")\n",
    "print(f\"   # Basic training with auto-save:\")\n",
    "print(f\"   model, data, history = train_model_enhanced(\")\n",
    "print(f\"       epochs=20,\")\n",
    "print(f\"       save_path='my_model.pt'  # Saves best model here\")\n",
    "print(f\"   )\")\n",
    "print(f\"\")\n",
    "print(f\"   # Load saved model later:\")\n",
    "print(f\"   model, data, history = load_model('my_model.pt')\")\n",
    "print(f\"\")\n",
    "print(f\"   # Use for translation:\")\n",
    "print(f\"   translation = generate('hello', model, data)\")\n",
    "\n",
    "print(f\"\\nðŸŽ‰ The enhanced training pipeline now automatically saves your best models!\")\n",
    "print(f\"ðŸ’¡ No more lost training progress - the best model is always preserved!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
